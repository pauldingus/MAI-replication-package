{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import ast  # Safely evaluates a string as a Python literal\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from datetime import datetime\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "# Data manipulation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import ListedColormap, to_rgba\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "\n",
    "# Geospatial libraries\n",
    "import rasterio\n",
    "from rasterio.warp import transform\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as tiles\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.geodesic as cgeo\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from owslib.wms import WebMapService\n",
    "\n",
    "# Database libraries\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "\n",
    "# Google Cloud\n",
    "from google.cloud import storage\n",
    "client = storage.Client()\n",
    "\n",
    "# Import statements that may have been commented out\n",
    "# from functions_activityForValidation import *\n",
    "\n",
    "# Color definitions\n",
    "maincolors = ['#2A9D8F', '#e9c46a', '#e76f51']\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "import ee\n",
    "ee.Initialize(project='p155mali1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters ##\n",
    "fontsize = 14 #4\n",
    "fs_title=16\n",
    "# Create a figure with specified dimensions\n",
    "fig, ax = plt.subplots(figsize=(25/2.54, 25/2.54))  # Convert from cm to inches\n",
    "\n",
    "image_paths = [\"forFigures/fig1_mkt_highres.png\", \"forFigures/fig1_nomkt_highres.png\", \"forFigures/img2.jpeg\", \"forFigures/img4.jpeg\"]\n",
    "labels = [\"Sun, 4 Sep 2022\", \"Wed, 25 Oct 2023\", \"Sun, 4 Sep 2022\", \"Wed, 7 Sep 2022\"]\n",
    "sizes = [.49,.235,.235,.235]\n",
    "size=0.235\n",
    "gap = (1- 4*.235)/3\n",
    "print(gap)\n",
    "x_corners = [i * (size + gap) for i in range(4)]\n",
    "y_corners = [1-sizes[0]-gap,1-2*sizes[1]-2*gap,1-sizes[2]-gap,1-sizes[3]-gap]\n",
    "labelcorners_pre =  [x_corners[0],x_corners[1]+gap/2, x_corners[2:4]]\n",
    "labelcorners = [item for sublist in labelcorners_pre for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "print(x_corners, labelcorners)\n",
    "c=-1\n",
    "for labcorner, size, path, corner, label, y_corner in zip(labelcorners,sizes, image_paths, x_corners, labels,y_corners):\n",
    "    c=c+1\n",
    "    ax.imshow(plt.imread(path), extent=[corner, corner+size, y_corner, y_corner+size-0.01])\n",
    "    if c==2 or c==3:\n",
    "        rect = patches.Rectangle((corner+0.03, 1-size-0.01), 0.05, 0.05, linewidth=1.5, edgecolor='lightgrey', facecolor='none', linestyle='dashed')\n",
    "        ax.add_patch(rect)\n",
    "    if c==1:\n",
    "        rect = patches.Rectangle((corner, y_corner), gap/3, 1*size-0.01, edgecolor='white', facecolor='white')\n",
    "        ax.add_patch(rect)\n",
    "        rect = patches.Rectangle((corner, y_corner+size-0.01), size,gap/3, edgecolor='white', facecolor='white')\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "ax.annotate('A', xy=(x_corners[0], 1-gap), xycoords='axes fraction', va='bottom', ha='left', weight='bold', fontsize=fs_title)\n",
    "ax.annotate('A marketplace in very-high-resolution imagery', xy=(.25, 1-gap), xycoords='axes fraction', va='bottom', ha='center', fontsize=fontsize)\n",
    "ax.annotate('B', xy=(x_corners[2], 1-gap), xycoords='axes fraction', va='bottom', ha='left', weight='bold', fontsize=fs_title)\n",
    "ax.annotate('The same marketplace in high-frequency imagery', xy=(.75, 1-gap), xycoords='axes fraction', va='bottom', ha='center', fontsize=fontsize)\n",
    "top_y =1-size-1.5*gap\n",
    "top_2 =1-sizes[0]-1.5*gap\n",
    "\n",
    "ax.annotate('C', xy=(0, top_2), xycoords='axes fraction', va='top', ha='left',  fontweight='bold', fontsize=fs_title)\n",
    "\n",
    "text = 'Subtract from each image a reference\\ncomposite to isolate differences'\n",
    "ax.annotate(text, xy=(0.25, top_2), xycoords='axes fraction', va='top', ha='center', fontsize=fontsize)\n",
    "\n",
    "ax.set_facecolor('white')  # Set facecolor to white\n",
    "ax.axis('off')\n",
    "ax.set_xlim(0, 1), ax.set_ylim(0, 1)\n",
    "for spine in ['top', 'right', 'bottom', 'left']:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "ax.tick_params(left = False, right = False , labelleft = False , \n",
    "                labelbottom = False, bottom = False) \n",
    "\n",
    "\n",
    "images = ['diffWed.jpeg', 'fig1_nomkt_highres.png','diffSun.jpeg','contourLines.png']\n",
    "c=-1\n",
    "hgt_i=0.235\n",
    "left_x = .5\n",
    "right_x=1\n",
    "bottom_y = .5\n",
    "ax.annotate('Sum differences by day-of-week across all\\nimages in sample for \\\\textbf{market detection}', \n",
    "                             xy=(1-hgt_i-gap/2,top_y), xycoords='data', va='top', ha='center', fontsize=fontsize)\n",
    "key = 1-hgt_i-gap/2\n",
    "top_3 =top_y-0.01\n",
    "ax.imshow(plt.imread(f\"forFigures/{images[2]}\"), extent=[x_corners[2], x_corners[2]+hgt_i, top_3-2*gap-hgt_i, top_3-2*gap])\n",
    "ax.imshow(plt.imread(f\"forFigures/{images[0]}\"), extent=[x_corners[3], 1, top_3-2*gap-hgt_i, top_3-2*gap])\n",
    "ax.imshow(plt.imread(f\"forFigures/{images[3]}\"), extent=[x_corners[2], x_corners[2]+hgt_i, top_3-3*gap-2*hgt_i, top_3-3*gap-hgt_i])\n",
    "ax.imshow(plt.imread(f\"forFigures/{images[1]}\"), extent=[x_corners[3], 1, top_3-3*gap-2*hgt_i, top_3-3*gap-hgt_i])\n",
    "print([right_x-hgt_i, right_x, bottom_y, top_y-hgt_i-gap])\n",
    "ax.annotate('Wednesdays', xy=(x_corners[3], top_3-2*gap), xycoords='data', va='top', ha='left', fontsize=fontsize,\n",
    "            bbox=dict(facecolor='white', edgecolor='white', boxstyle='square,pad=0.1'))\n",
    "ax.annotate('Sundays', xy=(x_corners[2],top_3-2*gap), xycoords='data', va='top', ha='left', fontsize=fontsize,\n",
    "            bbox=dict(facecolor='white', edgecolor='white', boxstyle='square,pad=0.1'))\n",
    "ax.annotate('D', xy=(x_corners[2],top_y), xycoords='axes fraction', va='top', ha='left',  fontweight='bold', fontsize=fs_title)\n",
    "\n",
    "\n",
    "wid = (right_x-2*hgt_i-5*gap) /3  # Height of the plot to occupy (20%)\n",
    "hei = .3 #image1.shape[1]/image1.shape[0]\n",
    "siz = 0.05\n",
    "up =.09\n",
    "top_y-top_y/3\n",
    "rows = [top_2-top_2*2/3-0.07, top_2-top_2/3-0.07] \n",
    "cols = [0, wid+gap, 2*wid+2*gap]\n",
    "dates=[\"Wednesday,\\n7 Sep 22\", \"Sunday,\\n4 Sep 22\"] #, \"Wed, 8 Jun 22\"]\n",
    "cats =[\"img\",\"comp\",\"diff\"]\n",
    "count=0\n",
    "for gg, (row, date) in enumerate(zip(rows, dates), start=0):\n",
    "    ggg=gg+1\n",
    "    g = row\n",
    "    cc=-1\n",
    "    for c in cols:\n",
    "        count=count+1\n",
    "        cc = cc+1\n",
    "        subfig = plt.figure()\n",
    "        subax = subfig.add_subplot(111, projection='3d')\n",
    "        if cats[cc]==\"comp\":\n",
    "            img = np.fliplr(np.array(Image.fromarray(plt.imread(f\"forFigures/{cats[cc]}2.jpeg\")).resize((50, 50)).rotate(270)))\n",
    "        else:\n",
    "            img = np.fliplr(np.array(Image.fromarray(plt.imread(f\"forFigures/{cats[cc]}{ggg}.jpeg\")).resize((50, 50)).rotate(270)))\n",
    "            \n",
    "        x = np.linspace(0, 1, img.shape[1])\n",
    "        y = np.linspace(0, 1, img.shape[0])\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        subax.plot_surface(X, Y, np.ones_like(X), facecolors=img/255, rstride=1, cstride=1, shade=False)\n",
    "        subax.tick_params(left = False, right = False , labelleft = False , \n",
    "                        labelbottom = False, bottom = False) \n",
    "        subax.set_xlim(0, 1), subax.set_ylim(0, 1), subax.set_zlim(0, 1)\n",
    "        subax.grid(False), subax.set_axis_off()\n",
    "        subax.set_xticks([]), subax.set_yticks([]), subax.set_zticks([])\n",
    "        plt.savefig(f\"forFigures/img{count}.png\", transparent=True, bbox_inches='tight', pad_inches=0)    \n",
    "        plt.close(subfig)\n",
    "        subfig.clf()\n",
    "        ax.imshow(mpimg.imread(f\"forFigures/img{count}.png\")[18:110, 15:205,:], extent=[c, c+wid, g-wid/4, g+wid/4])\n",
    "        if c==0 and gg==1:\n",
    "            ax.annotate(\"$\\\\vdots$\", xy=(0.03, g+1.6*up), xycoords='axes fraction', va='center', ha='left', fontsize=20, fontweight='bold')\n",
    "        if c==0 and gg==0:\n",
    "            ax.annotate(\"$\\\\vdots$\", xy=(0.03, g-1.5*wid/3), xycoords='axes fraction', va='bottom', ha='left', fontsize=20, fontweight='bold')\n",
    "        \n",
    "    ax.annotate('-', xy=(wid+gap-0.02, g), xycoords='axes fraction',\n",
    "                             xytext=(wid+gap-0.02, g), va='center', ha='center', fontsize=20)\n",
    "    ax.annotate('=', xy=(2*wid+1.5*gap, g), xycoords='axes fraction',\n",
    "                             xytext=(2*wid+1.5*gap, g), va='center', ha='center', fontsize=15)\n",
    "    \n",
    "    \n",
    "    desired_width = 50  # specify your desired width\n",
    "    desired_height = 50  # specify your desired height\n",
    "    image1_resized = np.fliplr(np.array(Image.fromarray(plt.imread(f\"forFigures/img2.jpeg\")).resize((desired_width, desired_height)).rotate(270)))\n",
    "\n",
    "    # Create figure and 3D axis\n",
    "    figComp = plt.figure()\n",
    "    axComp = figComp.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Create grid\n",
    "    x = np.linspace(0, 1, image1_resized.shape[1])\n",
    "    y = np.linspace(0, 1, image1_resized.shape[0])\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Plot each image as a surface at different heights\n",
    "    axComp.plot_surface(X, Y, np.ones_like(X), facecolors=image1_resized/255, rstride=1, cstride=1, shade=False)\n",
    "    axComp.plot_surface(X, Y, 2 * np.ones_like(X), facecolors=image1_resized/255, rstride=1, cstride=1, shade=False)\n",
    "    axComp.plot_surface(X, Y, 3 * np.ones_like(X), facecolors=image1_resized/255, rstride=1, cstride=1, shade=False)\n",
    "    axComp.plot_surface(X, Y, 4 * np.ones_like(X), facecolors=image1_resized/255, rstride=1, cstride=1, shade=False)\n",
    "    axComp.tick_params(left = False, right = False , labelleft = False , \n",
    "                    labelbottom = False, bottom = False) \n",
    "\n",
    "    axComp.set_xlim(0, 1), axComp.set_ylim(0, 1),  axComp.set_zlim(0, 6)\n",
    "    axComp.grid(False),axComp.set_axis_off()\n",
    "    axComp.set_xticks([]), axComp.set_yticks([]), axComp.set_zticks([])\n",
    "    plt.savefig(\"forFigures/composite.png\", transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(figComp)\n",
    "    figComp.clf()\n",
    "\n",
    "    ax.imshow(mpimg.imread('forFigures/composite.png'), extent=[1.25*wid+gap-siz, 1.25*wid+gap+siz, g+up-siz, g+up+siz])\n",
    "    if gg!=1:\n",
    "        #ax.annotate(\"$med()$\", xy=(1.25*wid+gap+siz, g+up), xycoords='axes fraction',va='center', ha='left', fontsize=fontsize)\n",
    "        pass\n",
    "    else:\n",
    "        text = \"Median over tempo-\\nrally adjacent images\\nwithin approx. ±6 wks.\"\n",
    "        ax.annotate(text, xy=(1.25*wid+gap+siz, g+up), xycoords='axes fraction', va='center', ha='left', fontsize=fontsize)\n",
    "    ax.annotate(\"$\\downarrow$\", xy=(1.25*wid+gap+siz, g+up-siz/2), xycoords='axes fraction', va='center', ha='right', fontsize=21)\n",
    "    ax.annotate(date, xy=(0, g+up), xycoords='axes fraction', va='center', ha='left', fontsize=fontsize)\n",
    "\n",
    "top=top_y-4.5*gap-2*hgt_i\n",
    "rows = [top*1/3-0.02, top*2/3-0.02]\n",
    "wid=top/2\n",
    "ax.annotate('E', xy=(right_x-2*hgt_i-gap,top), xycoords='axes fraction', va='top', ha='left',  fontweight='bold', fontsize=fs_title)\n",
    "ax.annotate('Sum differences by image within identified\\nmarket fringe for \\\\textbf{activity tracking}', \n",
    "                             xy=(key,top), xycoords='data', va='top', ha='center', fontsize=fontsize)\n",
    "\n",
    "gg=-1\n",
    "values=[[\".54\",\".76\",\".68\"],[\"5.32\",\"4.96\",\"5.08\"]]#,[\"1.12\",\".78\",\".92\"]]\n",
    "\n",
    "colors = maincolors\n",
    "for g in rows:\n",
    "    gg=gg+1\n",
    "    figComp = plt.figure()\n",
    "    axComp = figComp.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Create grid\n",
    "    x = np.linspace(0, 1, image1_resized.shape[1])\n",
    "    y = np.linspace(0, 1, image1_resized.shape[0])\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    for r in range(2,3):\n",
    "        image1_resized = np.fliplr(np.array(Image.fromarray(plt.imread(f\"forFigures/row{gg}_shape{r}.jpeg\")).resize((desired_width, desired_height)).rotate(180)))\n",
    "        image_rgba = np.zeros((image1_resized.shape[0], image1_resized.shape[1], 4), dtype=np.uint8)\n",
    "        image_rgba[:, :, :3] = image1_resized  # Copy RGB channels\n",
    "        image_rgba[:, :, 3] = 255  # Set alpha channel to opaque initially\n",
    "        black_pixels = (image_rgba[:, :, 0] == 0) & (image_rgba[:, :, 1] == 0) & (image_rgba[:, :, 2] == 0)\n",
    "        image_rgba[:, :, 3][black_pixels] = 0\n",
    "        axComp.plot_surface(X, Y, r *np.ones_like(X), facecolors=image_rgba/255, rstride=1, cstride=1, shade=False)\n",
    "    axComp.tick_params(left = False, right = False , labelleft = False , \n",
    "                    labelbottom = False, bottom = False) \n",
    "\n",
    "    # Set axis limits\n",
    "    axComp.set_xlim(0, 1), axComp.set_ylim(0, 1), axComp.set_zlim(0, 3)\n",
    "    axComp.grid(False)\n",
    "    axComp.set_xticks([]), axComp.set_yticks([]), axComp.set_zticks([])\n",
    "    axComp.set_axis_off()\n",
    "    plt.savefig(f\"forFigures/stack_row{gg}.png\", transparent=True, bbox_inches='tight', pad_inches=0)    \n",
    "\n",
    "    plt.close(figComp)\n",
    "    figComp.clf()\n",
    "    ax.imshow(mpimg.imread(f\"forFigures/stack_row{gg}.png\"), extent=[.585, 0.585+2.5*wid, g-2.5*wid/2-0.02, g+2.5*wid/2-0.02])\n",
    "\n",
    "    xcoor=.81\n",
    "    ycoor_anchor=g\n",
    "    rowsize=0.02\n",
    "    for v in range(1,2):\n",
    "        ycoor = -rowsize+ycoor_anchor+v*rowsize\n",
    "        string = ax.annotate(f\"$\\Sigma=${values[gg][v]}\", xy=(xcoor, ycoor), xycoords='axes fraction', va='center', ha='left', fontsize=fontsize, color='black')#colors[v]\n",
    "    if gg==1:\n",
    "        ax.annotate(\"$\\\\vdots$\", xy=(right_x-2*hgt_i-gap+0.03, g+0.04), xycoords='axes fraction', va='center', ha='left', fontsize=15, fontweight='bold')    \n",
    "    ax.annotate(dates[gg], xy=(right_x-2*hgt_i-gap, g), xycoords='axes fraction', va='center', ha='left', fontsize=fontsize, fontweight='bold')     \n",
    "ax.annotate(\"$\\\\vdots$\", xy=(right_x-2*hgt_i-gap+0.03, top*1/3-0.06), xycoords='axes fraction', va='center', ha='left', fontsize=15, fontweight='bold')    \n",
    "\n",
    "plt.rcParams['text.usetex'] = True  # Enable LaTeX\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "plt.savefig(f\"forFigures/Figure1.png\", transparent=True, bbox_inches='tight', pad_inches=0, dpi=300)    \n",
    "plt.show()\n",
    "\n",
    "plt.close(fig)\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of detected days for various threshold levels\n",
    "\n",
    "freqDayStr_short='w7'\n",
    "maxRank = 4 # exclude altitude levels above this\n",
    "ring_area_share = 0.8  # Only consider rings whose area is more than 100(1-X)% of the shape defining the outer border of the ring\n",
    "\n",
    "prefix = \"exports-mai2023\"\n",
    "varsOfInterest=['p50','sumsum', 'ccount']\n",
    "threshold_for_market=24\n",
    "bucket=client.get_bucket('exports-mai2023')\n",
    "\n",
    "forMerge=['ident','weekdayThisAreaIsActive','date','mktDay','mktID','locGroup','time','year','month', 'weekday', 'mkt_lat','mkt_lon','time_decimal'] \n",
    "patterns_to_drop = ['ground_control','strictnessRank', 'subStrictnessRank''Geography','origName_', 'coorLength_', '.geo', 'system:index_b0', 'system:index', 'weekday_','market']\n",
    "propToDrop=['quality_category','system:index', '.geo','order_id', 'pixel_resolution','gsd','provider', 'published', 'publishing_stage', 'item_type', 'item_id', 'snow_ice_percent', 'strip_id','updated']\n",
    "\n",
    "list_df_acrossLocs = []\n",
    "pd.set_option('display.width', 100)  # Set display width\n",
    "pd.set_option('display.max_columns', 500)  # Show all columns\n",
    "\n",
    "df1 = pd.read_csv('forFigures/malawi_validationMarkets.csv')\n",
    "df1['country'] = 'Malawi'\n",
    "df1.loc[df1['loc'] == 'lon35_0148lat-16_2', 'weekdays'] = \"2,6\" # based on visual inspection\n",
    "df1.loc[df1['loc'] == 'lon35_3223lat-15_6801', 'weekdays'] = \"3,0,6\" \n",
    "df1.loc[df1['loc'] == 'lon34_8547lat-15_4476', 'weekdays'] = \"2,6\" \n",
    "\n",
    "df2 = pd.read_csv('forFigures/kenya_validationMarkets.csv')\n",
    "df2['country'] = 'Kenya'\n",
    "df2.loc[df2['loc'] == 'lon1_0312lat34_9975', 'weekdays'] = \"2,0\" # based on visual inspection\n",
    "df2.loc[df2['loc'] == 'lon0_4892lat34_8373', 'weekdays'] = \"1\" \n",
    "\n",
    "df3 = pd.read_csv('forFigures/mozambique_validationMarkets.csv')\n",
    "df3['country'] = 'Mozambique'\n",
    "remove= ['lon40_6945lat-14_8443','lon39_5196lat-14_0691', 'lon40_5215lat-14_3051'] # only opened in 2023\n",
    "df3.loc[df3['loc'] == 'lon39_2759lat-15_1246', 'weekdays'] = '0' # based on visual inspection\n",
    "df3.loc[df3['loc'] == 'lon38_0526lat-16_9714', 'weekdays'] = '2'\n",
    "df3.loc[df3['loc'] == 'lon39_1221lat-15_0092', 'weekdays'] = '0'\n",
    "df3 = df3[~df3['loc'].isin(remove)].reset_index(drop=True)\n",
    "\n",
    "df_validation = pd.concat([df1, df2,df3], ignore_index=True)\n",
    "df_validation = df_validation[['loc', 'country', 'weekdays']]\n",
    "df_validation = df_validation.dropna(subset=['weekdays'])\n",
    "df_validation = df_validation.dropna(subset=['loc']).reset_index(drop=True)\n",
    "df_validation['weekdays'] = df_validation['weekdays'].str.replace(' ', ',')\n",
    "df_validation['weekdays'] = df_validation['weekdays'].str.replace(',,', ',')\n",
    "\n",
    "print(len(df_validation[df_validation['country']=='Malawi']['loc'].unique()))\n",
    "\n",
    "locs = df_validation['loc'].unique()\n",
    "\n",
    "## no exports because no shape detected with pipeline\n",
    "no_shapes = [\"lon-0_3438lat34_8801\",'lon0_3355lat34_6492','lon0_5214lat34_7107']\n",
    "no_shapes_simul = ['lon0_2067lat34_4904','lon0_1971lat34_6969','lon0_3355lat34_6492','lon39_1221lat-15_0092',\n",
    "                   'lon0_4413lat34_7168','lon35_6374lat-15_8082','lon0_7281lat34_8767','lon0_6563lat34_5907',\n",
    "                   'lon0_6511lat34_8766','lon0_604lat34_8756','lon0_5364lat34_4999','lon0_4845lat34_7496',\n",
    "                   'lon0_471lat34_315','lon0_4218lat34_4254','lon0_3816lat34_5842','lon0_3606lat34_4016'\n",
    "                  ]\n",
    "# no export because \"Computation timed out error\" \n",
    "no_03export=['lon35_4511lat-14_362','a']\n",
    "\n",
    "def check_file_exists(bucket, file_path):\n",
    "    \"\"\"Check if a file exists in a Google Cloud Storage bucket.\"\"\"\n",
    "    blob = bucket.blob(file_path)\n",
    "    return blob.exists()\n",
    "results_df = pd.DataFrame(columns=['loc', 'thres','detected_days','detected_days_simul'])\n",
    "results_df = results_df.astype('object')\n",
    "locsProb=['']\n",
    "locCount=0\n",
    "\n",
    "for exportType in ['Act5','Actval']:\n",
    "    for loc in sorted(locs, reverse=True):\n",
    "        print('loc', loc)\n",
    "        locCount=locCount+1\n",
    "        # Get the GEEbucket and locGroup for the current location\n",
    "        GEEbucket = checkLocationFileStatus(loc, 'bucket')\n",
    "        locGroup = checkLocationFileStatus(loc, 'locGroup')\n",
    "        print(loc, GEEbucket, locGroup)\n",
    "\n",
    "        # Read the activity CSV file\n",
    "        if exportType=='Act5' and (loc in no_shapes or loc in no_03export): \n",
    "            for t in range(8,31):\n",
    "                temp_df = pd.DataFrame({'loc': [loc], 'thres': [t], 'detected_days': [[]]})\n",
    "                results_df = pd.concat([results_df, temp_df], ignore_index=True)\n",
    "        elif exportType=='Actval' and (loc in no_shapes_simul):\n",
    "            for t in range(8,31):\n",
    "                results_df.loc[(results_df['loc'] == loc) & (results_df['thres'] == t), 'detected_days_simul'] = ''\n",
    "        else:\n",
    "            df = pd.read_csv(f'gs://exports-mai2023/{locGroup}/measures/export{exportType}_maxpMax{loc}_{freqDayStr_short}.csv')\n",
    "\n",
    "            # keep only entries that fall between the strictest rank we define and the least strict one for a given shape, but at least 30\n",
    "            minRank = max(df['strictnessRank'].min(),30)\n",
    "            df = df[(df['strictnessRank'] <= minRank) & (df['strictnessRank'] >= maxRank)]\n",
    "            df = df[((df['subStrictnessRank'] <= minRank) & (df['subStrictnessRank'] > maxRank)) | (pd.isna(df['subStrictnessRank'])) | (df['subStrictnessRank'] ==100) ]\n",
    "            print(df['strictnessRank'].unique().tolist())\n",
    "            df['subStrictnessRank'] = df['subStrictnessRank'].fillna(100).astype(int)\n",
    "\n",
    "            eligible_rings = df[df['subStrictnessRank'] != 100].groupby('strictnessRank', as_index=False)['subStrictnessRank'].max()\n",
    "            additional_rows = pd.DataFrame({\n",
    "                'strictnessRank': df['strictnessRank'].unique(),\n",
    "                'subStrictnessRank': 100\n",
    "            })\n",
    "            eligible_shapes = pd.concat([eligible_rings, additional_rows]).sort_values(by='strictnessRank').reset_index(drop=True)\n",
    "\n",
    "            df_elig =  pd.merge(df, eligible_shapes, on=['strictnessRank', 'subStrictnessRank'])\n",
    "\n",
    "            df_elig.rename(columns={'weekdayShp': 'weekdayThisAreaIsActive'}, inplace=True)\n",
    "\n",
    "            # Extract image id \n",
    "            df_elig['ident'] = df_elig['ident'].str.rsplit('_maxpMax', n=1).str[0].str[1:] \n",
    "            df_elig['weekdayThisAreaIsActive'] = df_elig['weekdayThisAreaIsActive'].astype(int)\n",
    "            df_elig['strictnessRank'] = df_elig['strictnessRank'].astype(int)\n",
    "\n",
    "            # Create area_id column from the strictnessRank variables\n",
    "            df_elig['strictnessRank_str'] = df_elig['strictnessRank'].apply(prepend_zero_if_single_digit)\n",
    "            df_elig['subStrictnessRank_str'] = df_elig['subStrictnessRank'].apply(prepend_zero_if_single_digit)\n",
    "            df_elig['area_id'] = df_elig['strictnessRank_str'].astype(str) + '_' + df_elig['subStrictnessRank_str'].astype(str)\n",
    "\n",
    "            geos = df_elig['area_id'].unique()\n",
    "\n",
    "            # Append area id to variable names\n",
    "            new_column_names = {old_col: old_col + '_maxpMax'  for old_col in varsOfInterest}\n",
    "            df_elig = df_elig.rename(columns=new_column_names)\n",
    "\n",
    "            # Assign info variables\n",
    "            df_elig = infoVars(df_elig, loc, locGroup)\n",
    "\n",
    "            # Identify market days\n",
    "            if exportType==\"Act5\": \n",
    "                for t in range(8,31):\n",
    "                    df_elig, localMktDays = identifyMktDays(df_elig,minRank, t)\n",
    "                    strings = [str(number) for number in localMktDays]\n",
    "                    temp_df = pd.DataFrame({'loc': [loc], 'thres': [t], 'detected_days': [strings]})\n",
    "                    #print('strings', strings)\n",
    "                    results_df = pd.concat([results_df, temp_df], ignore_index=True)\n",
    "            if exportType==\"Actval\":\n",
    "                for t in range(8,31):\n",
    "                    df_elig, localMktDays = identifyMktDays(df_elig,minRank, t)\n",
    "                    strings = [str(number) for number in localMktDays]\n",
    "                    results_df.loc[(results_df['loc'] == loc) & (results_df['thres'] == t), 'detected_days_simul'] = ','.join(map(str, strings))\n",
    "\n",
    "def safe_convert(s):\n",
    "    # Split the string by commas and filter out any empty strings\n",
    "    return [int(x) for x in s.split(',') if x.isdigit()]\n",
    "results_df['detected_days_simul'].fillna('', inplace=True)\n",
    "results_df['detected_days_simul'] = results_df['detected_days_simul'].apply(safe_convert)\n",
    "print(locsProb)\n",
    "\n",
    "df_merged = pd.merge(results_df, df_validation, on='loc', how='outer')\n",
    "\n",
    "# for each detected day value, set 1 if in actual day list, 0 otherwise\n",
    "def convert_string_to_list(s):\n",
    "    # Handle cases where the input might not be a string\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "\n",
    "    # Replace commas with spaces and split by spaces\n",
    "    items = s.replace(',', ' ').split()\n",
    "    \n",
    "    # Strip spaces and convert to strings\n",
    "    return [x.strip() for x in items if x.strip()]\n",
    "    \n",
    "def check_all_substrings(row):\n",
    "    if row['detected_days']:  # Check if varA is not empty\n",
    "        if row['detected_days'] and isinstance(row['detected_days'], list):\n",
    "            return int(all(day in row['weekdays'] for day in row['detected_days']))\n",
    "    return 0  # Return 0 if varA is empty\n",
    "df_merged['weekdays'] = df_merged['weekdays'].apply(convert_string_to_list)\n",
    "df_merged['detected_days'] = df_merged['detected_days'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "# Apply the function to each row and create a new column\n",
    "df_merged['valid'] = df_merged.apply(check_all_substrings, axis=1)\n",
    "#df_merged['weekdays'] = df_merged['weekdays'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df_merged)\n",
    "\n",
    "def precision(a_list, b_list):\n",
    "    return [1 if item in b_list else 0 for item in a_list]\n",
    "\n",
    "def recall(a_list, b_list):\n",
    "    return [1 if item in b_list else 0 for item in a_list]\n",
    "\n",
    "def fpr(a_list):\n",
    "    if a_list:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df_merged['precision'] = df_merged.apply(lambda row: precision(row['detected_days'], row['weekdays']), axis=1)\n",
    "df_merged['recall'] = df_merged.apply(lambda row: precision(row['weekdays'],row['detected_days']), axis=1)\n",
    "df_merged['fpr'] = df_merged.apply(lambda row: fpr(row['detected_days_simul']), axis=1)\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df_merged)\n",
    "print(len(df_merged[df_merged['country']=='Kenya']['loc'].unique()))\n",
    "print(len(df_merged[df_merged['country']=='Malawi']['loc'].unique()))\n",
    "print(len(df_merged[df_merged['country']=='Mozambique']['loc'].unique()))\n",
    "\n",
    "def mean_of_lists(series):\n",
    "    # Flatten all lists in the series\n",
    "    all_items = [item for sublist in series for item in sublist]\n",
    "    # Return the mean of all items or NaN if the list is empty\n",
    "    return np.mean(all_items) if all_items else np.nan\n",
    "\n",
    "# Group by 'varA' and apply the function to 'varB'\n",
    "collapse_by=['country','thres']\n",
    "prec = df_merged.groupby(collapse_by)['precision'].apply(mean_of_lists).reset_index()\n",
    "display(prec)\n",
    "rec = df_merged.groupby(collapse_by)['recall'].apply(mean_of_lists).reset_index()\n",
    "display(rec)\n",
    "df_merge1 = pd.merge(prec, rec, on=collapse_by, how='outer')\n",
    "\n",
    "df_collapsed = df_merged.groupby(collapse_by)['valid'].mean().reset_index()\n",
    "df_collapsed = pd.merge(df_collapsed, df_merge1, on=collapse_by, how='outer')\n",
    "df_collapsed1 = df_merged.groupby(collapse_by)['fpr'].mean().reset_index()\n",
    "df_collapsed = pd.merge(df_collapsed, df_collapsed1, on=collapse_by, how='outer')\n",
    "\n",
    "thres_range = np.sort(np.power(np.arange(2, -0.05, -0.05),4))[::-1]\n",
    "df_values = pd.DataFrame({\n",
    "    'thres': range(len(thres_range)),  # Index as a column\n",
    "    'cutoffs_orig_log': np.log(thres_range)                # Log-transformed values as a column\n",
    "})\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df_values)\n",
    "\n",
    "df_collapsed = pd.merge(df_collapsed, df_values, on='thres', how='outer')\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df_collapsed)\n",
    "fontsize=14\n",
    "\n",
    "\n",
    "## LEFT top panels ##\n",
    "titles =['Kenya', 'Malawi', 'Mozambique']\n",
    "\n",
    "subtitles =[f\" ({len(df_merged[df_merged['country']=='Kenya']['loc'].unique())} markets)\",\n",
    "            f\" ({len(df_merged[df_merged['country']=='Malawi']['loc'].unique())})\",\n",
    "            f\" ({len(df_merged[df_merged['country']=='Mozambique']['loc'].unique())})\"]\n",
    "print(titles, subtitles)\n",
    "lp_prec = 'solid' \n",
    "lp_rec = 'dashed'\n",
    "lp_acc = 'dotted'\n",
    "for build in range(0,4):\n",
    "    fig = plt.figure(figsize=(13/2.54, 20/2.54))  # Convert from cm to inches\n",
    "\n",
    "    # Define grid specification with adjusted height ratios\n",
    "    gs = GridSpec(1, 1, width_ratios=[1])  # 1 rows, 2 columns\n",
    "    left_ax = fig.add_subplot(gs[0, 0])  # Left portion\n",
    "    gap = 0.085\n",
    "    for spine in ['top', 'right', 'bottom', 'left']:\n",
    "        left_ax.spines[spine].set_visible(False)\n",
    "    left_ax.tick_params(left = False, right = False, labelleft = False, labelbottom = False, bottom = False) \n",
    "\n",
    "    left_topleft_ax = left_ax.inset_axes([0,   2*(1-2*gap)/3+2*gap, 1, (1-2*gap)/3]) \n",
    "    left_topmiddle_ax = left_ax.inset_axes([0, (1-2*gap)/3+gap, 1, (1-2*gap)/3]) \n",
    "    left_topright_ax = left_ax.inset_axes([0,   0, 1, (1-2*gap)/3])\n",
    "    axes = [left_topleft_ax,left_topmiddle_ax,left_topright_ax]\n",
    "\n",
    "    gap = 0.075\n",
    "\n",
    "    for p in range(0,3):\n",
    "        axes[p].annotate(titles[p]+subtitles[p],  ha='center', va='bottom', fontsize=fontsize, xy=(.5, 1.025), xycoords='axes fraction', color=maincolors[p])\n",
    "        df = df_collapsed[df_collapsed['country'] == titles[p]]\n",
    "        axes[p].plot(df['cutoffs_orig_log'], df['recall'], linestyle=lp_rec, color=maincolors[p], label='Recall',linewidth=3)\n",
    "        if build>0:\n",
    "            axes[p].plot(df['cutoffs_orig_log'], df['precision'], linestyle=lp_prec, color=maincolors[p], label='Precision',linewidth=3)\n",
    "        if build>1:\n",
    "            axes[p].plot(df['cutoffs_orig_log'], df['fpr'], linestyle=lp_acc, color=maincolors[p], label='False pos. rate',linewidth=3)\n",
    "        for spine in ['top', 'right']:\n",
    "            axes[p].spines[spine].set_visible(False)\n",
    "        axes[p].set_yticks([0,0.2,0.4,0.6,0.8,1])\n",
    "        axes[p].set_yticklabels([\"0\",\".2\",\".4\",\".6\",\".8\",\"1\"])\n",
    "        ticks = [1/16, 1/4, 1, 4]\n",
    "        ticks_str = [\"1/16\"  , \"1/4\", \"1\", \"4\"]\n",
    "        axes[p].set_xticks(np.log(ticks), ticks_str)\n",
    "\n",
    "        axes[p].set_ylim(-0.01, 1.01)  # Set x-axis limits from 1 to 4\n",
    "        axes[p].tick_params(labelsize=fontsize)\n",
    "        if build>2:\n",
    "            axes[p].axvline(df_values.loc[df_values['thres'] == 24, 'cutoffs_orig_log'].iloc[0], color='gray', linestyle='--', linewidth=2, label='')\n",
    "\n",
    "    axes[2].set_xlabel('Cumulative differences per weekday',fontsize=fontsize)\n",
    "    left_ax.tick_params(left = False, right = False, labelleft = False, labelbottom = False, bottom = False) \n",
    "    axes[0].annotate('Recall',  xycoords='axes fraction',xy=(.9, 0.3), xytext=(.9, .5), arrowprops=dict(arrowstyle='->', color='gray'), fontsize=fontsize, color='gray',ha='center')\n",
    "    if build>0:\n",
    "        axes[0].annotate('Precision', xycoords='axes fraction', xy=(.9, 1), xytext=(.9, .75), arrowprops=dict(arrowstyle='->', color='gray'), fontsize=fontsize, color='gray',ha='center')\n",
    "    if build>1:     \n",
    "        axes[0].annotate('False pos. rate', xycoords='axes fraction', xy=(0.7, 0), xytext=(.7, .175), arrowprops=dict(arrowstyle='->', color='gray'), fontsize=fontsize, color='gray',ha='center', va='bottom')\n",
    "    if build>2:\n",
    "        axes[1].annotate('Chosen\\ncutoff for\\nmapping', xy=(np.log(0.40959999999999963), 0.2), xytext=(np.log(1/8), 0.2), arrowprops=dict(arrowstyle='->', color='gray'), fontsize=fontsize, color='gray',ha='center', va='center')\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "    plt.savefig(f\"forFigures/Figure2_{build}.png\", transparent=True, bbox_inches='tight', pad_inches=0, dpi=300)    \n",
    "    plt.show()\n",
    "\n",
    "    plt.close(fig)\n",
    "    fig.clf()\n",
    "\n",
    "display(df_collapsed[df_collapsed['thres'] == 24])\n",
    "display(df_collapsed.groupby('country')['valid'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target scale (1km) for population density maps\n",
    "tgtScale = 1000\n",
    "# Target scale (1km) for gridcells. May need to be exported as an asset\n",
    "tgtScale2 = 1000\n",
    "\n",
    "# limits for pop-density in map\n",
    "limits = [0, 100, 250, 500, 1000, 100000]\n",
    "limit_labels = [\"<100\", \"<250\", \"<500\", \"<1,000\", \">1,000\"]\n",
    "\n",
    "country = \"Ethiopia\"\n",
    "country_short = \"ETH\"\n",
    "\n",
    "# Colors for map\n",
    "color1 = \"#e9c56a\"\n",
    "color2 = \"#2A9D8F\"\n",
    "color3 = \"#e76f51\"\n",
    "\n",
    "# Generate 5 evenly spaced colors between white and black\n",
    "colors = [mcolors.to_hex((v, v, v)) for v in np.linspace(1, 0, len(limits) - 1)]\n",
    "\n",
    "# Length of scale bar at specific latitude\n",
    "latitude = 10  # Example latitude (in degrees)\n",
    "km = 100  # Distance in kilometers (100 km)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shared inputs across subfigures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_boundaries_shp = ee.FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\").filter(\n",
    "    ee.Filter.eq(\"country_na\", country)\n",
    ") \n",
    "\n",
    "worldpop = ee.Image(ee.ImageCollection(\"JRC/GHSL/P2023A/GHS_POP\").filterDate('2020-01-01','2021-01-01').first()).clip(eth_boundaries_shp)\n",
    "worldpop = worldpop.set('system:footprint', eth_boundaries_shp.geometry())\n",
    "worldpop_scale = 100\n",
    "addis =ee.FeatureCollection(\"projects/ethiopia-candidate-locs/assets/cityMask\").first().geometry()\n",
    "worldpop_without_addis = worldpop.clip(eth_boundaries_shp.geometry().difference(addis))\n",
    "\n",
    "eth_boundaries = geemap.ee_to_geojson(\n",
    "    eth_boundaries_shp\n",
    ")  # Export the asset to a GeoJSON file\n",
    "eth_boundaries = json.dumps(eth_boundaries)  # Convert back to string\n",
    "eth_boundaries = StringIO(eth_boundaries)  # Create file-like object\n",
    "eth_boundaries = gpd.read_file(\n",
    "    eth_boundaries\n",
    ")  # Load the GeoJSON file into a GeoDataFrame\n",
    "\n",
    "pop_addis = worldpop.reduceRegion(\n",
    "  geometry = ee.FeatureCollection(\"projects/ethiopia-candidate-locs/assets/cityMask\").first().geometry(),\n",
    "  reducer = ee.Reducer.sum(),\n",
    "  scale = worldpop.projection().nominalScale()\n",
    ").get('population_count').getInfo()\n",
    "print('pop_addis', pop_addis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIGURE 3A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and process a population density map   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the scale adjustment factor\n",
    "factor = ee.Number(worldpop_scale).pow(2).divide(ee.Number(tgtScale).pow(2))\n",
    "\n",
    "# Rescale to 1km resolution\n",
    "worldpop_1km = (\n",
    "    worldpop.divide(factor)\n",
    "    .reduceResolution(reducer=ee.Reducer.mean(), bestEffort=True)\n",
    "    .reproject(crs=worldpop.projection(), scale=tgtScale)\n",
    ")\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(worldpop_1km.gt(0).And(worldpop_1km.lt(100)).selfMask())\n",
    "Map.centerObject(worldpop)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate binary masks and export each to a GeoTIFF\n",
    "for i in range(len(limits) - 1):\n",
    "    print(f\"between {limits[i]} and {limits[i + 1]}\")\n",
    "    mask = worldpop_1km.gte(limits[i]).And(worldpop_1km.lt(limits[i + 1])).selfMask()\n",
    "    try:\n",
    "        geemap.ee_to_geotiff(\n",
    "            mask,\n",
    "            f\"temp/im{i}.tif\",\n",
    "            resolution=tgtScale,\n",
    "            crs=\"EPSG:4326\",\n",
    "            quiet=True,\n",
    "            to_cog=False,\n",
    "            bbox= [32,-2,52,15]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        if \"Permission denied\" in str(e):\n",
    "            print(\n",
    "                f\"Permission denied for file: im{i}.tif (verify whether created anyway)\"\n",
    "            )\n",
    "        else:\n",
    "            print(e)\n",
    "            stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load latest set of detected marketplaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "       SELECT marketLat, marketLon FROM `mai-database`.`location_file` lf\n",
    "        WHERE to_delete IS NULL\n",
    "        AND 00DownStatus IN (\"complete\",\"updating\")\n",
    "        AND country=\"{country}\"\n",
    "        AND (false_positive IN (-1,0) OR false_positive IS NULL)\n",
    "        AND EXISTS(\n",
    "            SELECT 1 FROM process_runs pr2\n",
    "            WHERE pr2.Location=lf.Location\n",
    "            AND Setup=\"MpM6\"\n",
    "            AND Status=\"complete\"\n",
    "        )\n",
    "        AND NOT EXISTS(\n",
    "            SELECT 1 FROM process_runs pr\n",
    "            WHERE pr.Location=lf.Location\n",
    "            AND Setup=\"MpM6\" \n",
    "            AND runAnyway=\"no\"\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "def create_gdf_from_markets(df):\n",
    "    \"\"\"Convert a DataFrame with 'marketLat' and 'marketLon' into a GeoDataFrame.\"\"\"\n",
    "    df[\"geometry\"] = df.apply(\n",
    "        lambda row: Point(row[\"marketLon\"], row[\"marketLat\"]), axis=1\n",
    "    )\n",
    "    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")  # Assuming WGS84\n",
    "\n",
    "\n",
    "def shpFromQuery(query):\n",
    "    df = pd.read_sql(query, engine)\n",
    "    df = df[df[\"marketLat\"].notnull()]\n",
    "    gdf = create_gdf_from_markets(df)\n",
    "    print(\"# markets:\", len(gdf))\n",
    "    return gdf\n",
    "\n",
    "\n",
    "market_centroids = shpFromQuery(query)\n",
    "display(market_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate length of scalebar for map   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longitude_degrees_for_km(latitude, km):\n",
    "    # Convert latitude to radians\n",
    "    latitude_rad = math.radians(latitude)\n",
    "\n",
    "    # Distance of 1 degree of longitude in kilometers at the given latitude\n",
    "    distance_per_degree = 111.32 * math.cos(latitude_rad)\n",
    "\n",
    "    # Calculate the number of degrees of longitude that correspond to the given km\n",
    "    longitude_degrees = km / distance_per_degree\n",
    "    return longitude_degrees\n",
    "\n",
    "\n",
    "longitude_degrees = longitude_degrees_for_km(latitude, km)\n",
    "print(\n",
    "    f\"{km} km corresponds to {longitude_degrees:.6f} degrees of longitude at latitude {latitude}°.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to plot the population density map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster_with_crs(im, ax, cmap=ListedColormap([\"white\", \"blue\"])):\n",
    "    filename = f\"temp/im{im}.tif\"\n",
    "    with rasterio.open(filename) as src:\n",
    "        # Read the raster data (first band)\n",
    "        raster_data = src.read(1)\n",
    "\n",
    "        # Get the raster transform and CRS\n",
    "        transform_matrix = src.transform\n",
    "        original_crs = src.crs  # Get original CRS\n",
    "        target_crs = \"EPSG:4326\"  # Define target CRS\n",
    "\n",
    "        # Get raster dimensions\n",
    "        height, width = raster_data.shape\n",
    "\n",
    "        # Create row and column indices\n",
    "        rows, cols = np.meshgrid(np.arange(height), np.arange(width), indexing=\"ij\")\n",
    "\n",
    "        # Convert row/col indices to spatial coordinates in the original CRS\n",
    "        x, y = rasterio.transform.xy(transform_matrix, rows, cols)\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # Reproject coordinates to EPSG:4326 if necessary\n",
    "        if original_crs != target_crs:\n",
    "            lon, lat = transform(original_crs, target_crs, x.flatten(), y.flatten())\n",
    "            lon = np.array(lon).reshape(x.shape)\n",
    "            lat = np.array(lat).reshape(y.shape)\n",
    "        else:\n",
    "            lon, lat = x, y  # If already in EPSG:4326, use as is\n",
    "\n",
    "        # Get extent in EPSG:4326\n",
    "        min_lon, max_lon = lon.min(), lon.max()\n",
    "        min_lat, max_lat = lat.min(), lat.max()\n",
    "\n",
    "        # Plot the raster data with proper extent\n",
    "        ax.imshow(\n",
    "            raster_data,\n",
    "            cmap=cmap,\n",
    "            interpolation=\"none\",\n",
    "            extent=(min_lon, max_lon, min_lat, max_lat),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put everything in a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# )  # Create a figure with size 16x16 inches\n",
    "def plot_population_and_markets(ax, one, two):\n",
    "    # Read the raster data\n",
    "    for im in range(0, 5):\n",
    "        plot_raster_with_crs(im, ax, cmap=ListedColormap([\"none\", colors[im]]))\n",
    "\n",
    "    # Plot the market centroids (assuming market_centroids is already a GeoDataFrame with the 'geometry' column)\n",
    "    market_centroids.plot(\n",
    "        ax=ax, facecolor=\"none\", edgecolor=color3, marker=\"o\", markersize=12, label=\"Detected marketplaces\", alpha=1\n",
    "    )\n",
    "\n",
    "    # Plot the Ethiopia boundaries\n",
    "    eth_boundaries.plot(ax=ax, color=\"none\", edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "    legend_patches = [\n",
    "        mpatches.Patch(\n",
    "            facecolor=colors[i],\n",
    "            label=limit_labels[i],\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "        for i in range(len(limits) - 1)\n",
    "    ]\n",
    "\n",
    "    legend_title = mpatches.Patch(\n",
    "        facecolor='none',  # Transparent fill\n",
    "        edgecolor='none',  # No border\n",
    "        label=\"People per km²:\"  # Leading spaces to align\n",
    "    )\n",
    "\n",
    "    market_legend = mlines.Line2D(\n",
    "        [],\n",
    "        [],\n",
    "        color=color3,\n",
    "        markerfacecolor=\"none\",\n",
    "        linestyle=\"none\",\n",
    "        markeredgecolor=color3,\n",
    "        marker=\"o\",\n",
    "        markersize=7,\n",
    "        label=\"Detected marketplaces\",\n",
    "    )\n",
    "\n",
    "    #legend_patches = [legend_title] + legend_patches    \n",
    "    \n",
    "    leg = ax.legend(\n",
    "        handles=legend_patches,\n",
    "        loc=\"upper left\",\n",
    "        frameon=False,\n",
    "        bbox_to_anchor=(.75, .97),\n",
    "        borderaxespad=0,\n",
    "    )\n",
    "    leg.set_title(\"\\n  People per km²:\", prop={\"size\": 10})\n",
    "    ax.add_artist(leg)\n",
    "    #leg.get_title().set_multialignment(\"center\")\n",
    "    \n",
    "    legend1 = ax.legend(handles=[market_legend], loc='upper left', frameon=False, bbox_to_anchor=(0.75, 1), borderaxespad=0)\n",
    "    ax.add_artist(legend1)\n",
    "\n",
    "    fontprops = fm.FontProperties(size=12)\n",
    "    scalebar = AnchoredSizeBar(\n",
    "        ax.transData,\n",
    "        longitude_degrees,\n",
    "        f\"{km} km\",\n",
    "        \"lower left\",\n",
    "        pad=0,\n",
    "        color=\"black\",\n",
    "        frameon=False,\n",
    "        size_vertical=0.05,\n",
    "        fontproperties=fontprops,\n",
    "    )\n",
    "    scalebar.set_bbox_to_anchor((one, two), transform=ax.transAxes)\n",
    "    ax.add_artist(scalebar)\n",
    "\n",
    "    # Set the minimum limit for the y-axis to this latitude and an arbitrary max limit\n",
    "    ax.set_ylim(bottom=eth_boundaries.total_bounds[1], top=eth_boundaries.total_bounds[3])\n",
    "    ax.set_xlim(left=eth_boundaries.total_bounds[0], right=eth_boundaries.total_bounds[2])\n",
    "\n",
    "    # Add labels and display the map\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.text(\n",
    "        -0,\n",
    "        1,\n",
    "        \"A\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "        verticalalignment=\"top\",\n",
    "        horizontalalignment=\"left\",\n",
    "    )\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIGURE 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## concentric rings around marketplaces\n",
    "geo = eth_boundaries_shp.first().geometry(5)\n",
    "\n",
    "market_centroids = market_centroids#.to_crs(epsg=32637)\n",
    "markets_fc = geemap.geopandas_to_ee(market_centroids)#.limit(500)\n",
    "rings = ee.FeatureCollection(ee.List([1000, 2000, 5000,10000,20000]).map(\n",
    "    lambda r: markets_fc\n",
    "             .map(lambda m: ee.Feature(m.buffer(r).simplify(ee.Number(r).divide(2)).intersection(geo,ee.Number(r).divide(2))))\n",
    "             .union(ee.Number(r).divide(2)).first().set('radius',r))).map(\n",
    "        lambda f: ee.Feature(f).set('area_km2', ee.Feature(f).area().divide(1e6))\n",
    "    )#.merge(ee.FeatureCollection(ee.Feature(geo).set('radius',999999, 'area_km2',geo.area().divide(1e6))))\n",
    "             \n",
    "print(rings.aggregate_mean('radius').getInfo())\n",
    "print(rings.aggregate_min('area_km2').getInfo(),rings.aggregate_mean('area_km2').getInfo(),rings.aggregate_max('area_km2').getInfo() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "grid_w_pop = (\n",
    "    worldpop.reduceRegions(\n",
    "        collection = rings, #grid.randomColumn().limit(5,'random'), #.sort('random')\n",
    "        reducer = ee.Reducer.sum(),\n",
    "        scale = worldpop.projection().nominalScale(),\n",
    "        tileScale = 16,\n",
    "    ).select([\"sum\", \"area_km2\",\"radius\"], [\"population\", \"area_km2\",\"radius\"])\n",
    ")\n",
    "\n",
    "task = ee.batch.Export.table.toAsset(\n",
    "    collection=grid_w_pop,\n",
    "    description='export_grid_w_pop',\n",
    "    assetId = \"projects/planetupload/assets/cleanedLocs/\"+country+\"_ringsghsl\"\n",
    ")\n",
    "\n",
    "# Start the task\n",
    "task.start()\n",
    "\n",
    "grid_w_pop_without_addis = (\n",
    "    worldpop_without_addis.reduceRegions(\n",
    "        collection = rings, #grid.randomColumn().limit(5,'random'), #.sort('random')\n",
    "        reducer = ee.Reducer.sum(),\n",
    "        scale = worldpop.projection().nominalScale(),\n",
    "        tileScale = 16,\n",
    "    ).select([\"sum\", \"area_km2\",\"radius\"], [\"population\", \"area_km2\",\"radius\"])\n",
    ")\n",
    "\n",
    "task = ee.batch.Export.table.toAsset(\n",
    "    collection=grid_w_pop_without_addis,\n",
    "    description='export_grid_w_pop',\n",
    "    assetId = \"projects/planetupload/assets/cleanedLocs/\"+country+\"_ringsghsl_withoutaddis\"\n",
    ")\n",
    "\n",
    "# Start the task\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_w_pop = ee.FeatureCollection(\n",
    "    f\"projects/planetupload/assets/cleanedLocs/{country}_ringsghsl\"\n",
    ")\n",
    "print(grid_w_pop.aggregate_mean(\"population\").getInfo(), grid_w_pop.size().getInfo())\n",
    "grid_w_pop_without_addis = ee.FeatureCollection(\n",
    "    f\"projects/planetupload/assets/cleanedLocs/{country}_ringsghsl_withoutaddis\"\n",
    ")\n",
    "print(grid_w_pop_without_addis.aggregate_mean(\"population\").getInfo(), grid_w_pop_without_addis.size().getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = geemap.ee_to_gdf(grid_w_pop)\n",
    "df_b_noaddis = geemap.ee_to_gdf(grid_w_pop_without_addis)\n",
    "df_b = df_b.merge(df_b_noaddis[['radius','population']], on='radius', suffixes=('', '_noaddis'))\n",
    "print(\"done\")\n",
    "display(df_b)\n",
    "display(df_b_noaddis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_share_plot(ax):\n",
    "\n",
    "\n",
    "    # Sort the dataframe by 'distance_to_market'\n",
    "    #df_bb = df_b.sort_values(by='nearest_mkt_km')\n",
    "    df_bb = df_b.sort_values(by='radius')\n",
    "    df_bb['radius_km'] = df_bb['radius']/1000\n",
    "    # Calculate the total population and area\n",
    "    total_population = 109628500 # https://www.portal.worldpop.org/ df_b[df_b['radius']=999999][\"population\"] #df_bb['population'].sum()\n",
    "    total_population_noaddis = 103971800 # https://www.portal.worldpop.org/ df_b[df_b['radius']=999999][\"population\"] #df_bb['population'].sum()\n",
    "    total_area = 1133384 # df_b[df_b['radius']=999999][\"area_km2\"]\n",
    "\n",
    "    # Calculate the cumulative sum of population and area\n",
    "    df_bb['cumulative_population'] = df_bb['population'].cumsum()\n",
    "    df_bb['cumulative_area'] = df_bb['area_km2'].cumsum()\n",
    "\n",
    "    # Calculate the cumulative share of population and area\n",
    "    df_bb['population_share'] = 100 * df_bb['population'] / total_population\n",
    "    df_bb['population_share_noaddis'] = 100 * df_bb['population_noaddis'] / total_population_noaddis\n",
    "    df_bb['area_share'] = 100 * df_bb['area_km2'] / total_area\n",
    "\n",
    "    # Optional: if you want to only keep the relevant columns\n",
    "    df_bb=df_bb[df_bb['radius']<50000]\n",
    "    df_bb = df_bb[['radius_km', 'population_share', 'area_share','population_share_noaddis']]\n",
    "    display(df_bb)\n",
    "\n",
    "    df_bbb = df_bb #df_bb[df_bb['nearest_mkt_km'] < 50]\n",
    "\n",
    "\n",
    "    #fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    x_vals = range(len(df_bbb))  # Even spacing by row\n",
    "    def format_label(x):\n",
    "        return str(int(x)) if x == int(x) else f\"{x:.1f}\"\n",
    "\n",
    "    labels = df_bbb['radius_km'].map(format_label)\n",
    "\n",
    "    # Plot the data\n",
    "    ax.bar(x_vals, df_bbb['population_share_noaddis'], label='Population excl. Addis Ababa',color=\"none\", edgecolor=color3, linewidth=1.25, linestyle='--')\n",
    "    ax.bar(x_vals, df_bbb['population_share'], label='Population',color=\"none\", edgecolor=color3, linewidth=1.25)\n",
    "    ax.bar([x + 0 for x in x_vals], df_bbb['area_share'], label='Area',color=\"none\",edgecolor=colors[2], linewidth=1.25, width=0.5 )\n",
    "    ax.set_xticks(x_vals)\n",
    "    ax.set_xticklabels(labels)\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Distance from nearest detected marketplace (km)')\n",
    "    ax.set_ylabel('Share within given distance')\n",
    "    ax.set_title('')\n",
    "\n",
    "    # Add a legend and grid\n",
    "    ax.legend(frameon=False)\n",
    "    ax.grid(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    # Add text\n",
    "    ax.text(\n",
    "        -0.15,\n",
    "        1,\n",
    "        \"B\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "        verticalalignment=\"top\",\n",
    "        horizontalalignment=\"left\",\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "    SELECT date, mktDay, Location FROM activity_market am\n",
    "    WHERE date>'2017-07-01' AND date<='2024-12-31'\n",
    "    AND EXISTS(\n",
    "        SELECT 1 FROM location_file lf\n",
    "        WHERE lf.Location = am.Location\n",
    "        AND country=\"{country}\"\n",
    "        AND (false_positive IN (-1,0) OR false_positive IS NULL)\n",
    "    )\n",
    "'''\n",
    "\n",
    "df_c = pd.read_sql(query, engine)\n",
    "df_c[\"month\"] = df_c[\"date\"].dt.month\n",
    "df_c[\"year\"] = df_c[\"date\"].dt.year\n",
    "#df_c[\"monthly_date\"] = (df_c[\"date\"].dt.year - 2016) * 12 + df_c[\"month\"]\n",
    "display(df_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\\\Users\\\\tillmanv\\Dropbox\\\\MarketActivityIndex\\\\mai_shared\\datasets\\weather\\clouds_at_markets'  # Change this to your actual path\n",
    "# from cloud_prob.ipynb\n",
    "# Initialize list to store DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop through files\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\") and filename.startswith(\"cloud_prob_\"):\n",
    "        # Extract year and month using regex\n",
    "        match = re.search(r'cloud_prob_(\\d{4})_(\\d{2})\\.csv', filename)\n",
    "        if match:\n",
    "            year = int(match.group(1))\n",
    "            month = int(match.group(2))\n",
    "\n",
    "            # Read the CSV\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Add year and month columns\n",
    "            df['year'] = year\n",
    "            df['month'] = month\n",
    "\n",
    "            # Append to list\n",
    "            df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Optional: check result\n",
    "print(final_df.head())\n",
    "\n",
    "monthly_avg_cloud = final_df.groupby('month')['cloud_percentage'].mean().reset_index()\n",
    "\n",
    "# Optional: sort by month\n",
    "monthly_avg_cloud = monthly_avg_cloud.sort_values('month')\n",
    "\n",
    "# Display result\n",
    "print(monthly_avg_cloud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_per_month(ax):\n",
    "    countsByMonthAndMkt = (\n",
    "        df_c.groupby([\"month\",\"year\", \"Location\"])[\"mktDay\"].sum().reset_index()\n",
    "    )\n",
    "\n",
    "    # Avg. observations per month and market\n",
    "    countsByMonth = (\n",
    "        countsByMonthAndMkt.groupby([\"month\",'year'])[\"mktDay\"].mean().reset_index()\n",
    "    )\n",
    "    #countsByMonth = countsByMonth[countsByMonth[\"year\"] <= 2024 & countsByMonth[\"year\"] >= 2017 ]\n",
    "    years = sorted(countsByMonth[\"year\"].unique())\n",
    "    n_years = len(years)\n",
    "    rgba_transparent = mcolors.to_rgba(color3, alpha=0.4)  # more transparent\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_gradient\", ['gray', color3], N=n_years)\n",
    "\n",
    "    for i, year in enumerate(years):\n",
    "        year_data = countsByMonth[countsByMonth[\"year\"] == year]\n",
    "        x = year_data[\"month\"]\n",
    "        y = year_data[\"mktDay\"]\n",
    "\n",
    "        # Interpolate to get a smooth curve\n",
    "        x_new = np.linspace(x.min(), x.max(), 50)  # More points for a smooth curve\n",
    "        spline = make_interp_spline(x, y, k=3)  # k=3 for cubic spline\n",
    "        y_smooth = spline(x_new)\n",
    "\n",
    "        ax.plot(\n",
    "            x_new,\n",
    "            y_smooth,\n",
    "            label=str(year),\n",
    "            color=cmap(i / (n_years - 1)),\n",
    "            linewidth=1.25\n",
    "        )\n",
    "\n",
    "    plt.xticks(ticks=range(1, 13), labels=[\n",
    "        \"Jan\", \"\", \"Mar\", \"\", \"May\", \"\",\n",
    "        \"Jul\", \"\", \"Sep\", \"\", \"Nov\", \"\"\n",
    "    ])\n",
    "    # Adding labels and title\n",
    "    ax.set_ylabel(\"Mean # of market-day\\nobs. per market & month\")\n",
    "    ax.set_xlabel(\"Month of year\")\n",
    "    ticks = [\n",
    "        13,\n",
    "        25,\n",
    "        37,\n",
    "        49,\n",
    "        61,\n",
    "        73,\n",
    "        85,\n",
    "        97,\n",
    "    ]  # Months at which we want the labels (e.g., 1/2016, 1/2017, ...)\n",
    "    labels = [\n",
    "        \"1/2017\",\n",
    "        \"1/18\",\n",
    "        \"1/19\",\n",
    "        \"1/20\",\n",
    "        \"1/21\",\n",
    "        \"1/22\",\n",
    "        \"1/23\",\n",
    "        \"1/24\",\n",
    "    ]  # Corresponding labels\n",
    "\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.set_facecolor(\"none\")\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_xlim(0.5, 12.5)  # Ensures months 1–12 align center-wise\n",
    "    ax.set_xticks(range(1, 13))\n",
    "    ax.text(\n",
    "        -0.15,\n",
    "        1,\n",
    "        \"C\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "        verticalalignment=\"top\",\n",
    "        horizontalalignment=\"left\",\n",
    "    )\n",
    "\n",
    "    label_years = [2017, 2019, 2020, 2023,2024]\n",
    "\n",
    "    for year in label_years:\n",
    "        data = countsByMonth[(countsByMonth[\"year\"] == year) & (countsByMonth[\"month\"] == 12)]\n",
    "        if not data.empty:\n",
    "            x = data[\"month\"].values[0]\n",
    "            y = data[\"mktDay\"].values[0]\n",
    "            ax.text(\n",
    "                x + 0.2, y,               # Slightly to the right of December\n",
    "                str(year),\n",
    "                color=cmap(years.index(year) / (n_years - 1)),  # Match line color\n",
    "                fontsize=10,\n",
    "                verticalalignment='center',\n",
    "                horizontalalignment='left'\n",
    "            )\n",
    "\n",
    " \n",
    "def add_cloud_bar(ax4):\n",
    "    # Compute mean cloud percentage by month\n",
    "\n",
    "    # Plot bar chart\n",
    "    ax4.bar(\n",
    "        monthly_avg_cloud[\"month\"],\n",
    "        monthly_avg_cloud[\"cloud_percentage\"],\n",
    "        width=0.6,\n",
    "        color='lightgray',\n",
    "        alpha=0.8\n",
    "    )\n",
    "    \n",
    "    max_cloud = monthly_avg_cloud[\"cloud_percentage\"].max()\n",
    "    max_rounded = np.ceil(max_cloud) \n",
    "\n",
    "\n",
    "    # Style and labels\n",
    "    ax4.set_ylabel(\"Avg. cloud %\", color='gray')\n",
    "    #ax2.set_xlabel(\"Month of year\")\n",
    "    ax4.tick_params(axis='y', labelcolor='gray')\n",
    "    ax4.set_ylim(0, 100)\n",
    "    ax4.set_xlim(0.5, 12.5)\n",
    "    ax4.set_xticks(range(1, 13))\n",
    "    ax4.set_xticklabels([\n",
    "        \"Jan\", \"\", \"Mar\", \"\", \"May\", \"\", \"Jul\", \"\", \"Sep\", \"\", \"Nov\", \"\"\n",
    "    ])\n",
    "    ax4.spines[\"top\"].set_visible(False)\n",
    "    ax4.spines[\"right\"].set_visible(False)\n",
    "    ax4.set_yticks([0, max_rounded])\n",
    "    ax4.set_yticklabels([str(0), str(int(max_rounded))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Stage One: Create figure and plot ax1\n",
    "fig = plt.figure(figsize=(12, 12), dpi=100, constrained_layout=True)\n",
    "g = 32  # grid granularity\n",
    "gs = GridSpec(g, g, figure=fig)\n",
    "\n",
    "# ax1: Top panel spanning full width of top 24 rows\n",
    "ax1 = fig.add_subplot(gs[:20, :])\n",
    "plot_population_and_markets(ax1, 0.75, 0.67)\n",
    "\n",
    "# 2. Stage Two: Add the lower two panels afterward\n",
    "ax2 = fig.add_subplot(gs[21:, : int(g / 2) - 1])\n",
    "ax3 = fig.add_subplot(gs[21:30, int(g / 2) + 1:])\n",
    "ax4 = fig.add_subplot(gs[30:, int(g / 2) + 1:])\n",
    "\n",
    "pop_share_plot(ax2)\n",
    "obs_per_month(ax3)\n",
    "add_cloud_bar(ax4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "       SELECT marketLat, marketLon, marketDays FROM `mai-database`.`location_file` lf\n",
    "        WHERE to_delete IS NULL\n",
    "        AND 00DownStatus IN (\"complete\",\"updating\")\n",
    "        AND country=\"{country}\"\n",
    "        AND (false_positive IN (-1,0) OR false_positive IS NULL)\n",
    "        AND EXISTS(\n",
    "            SELECT 1 FROM process_runs pr2\n",
    "            WHERE pr2.Location=lf.Location\n",
    "            AND Setup=\"MpM6\"\n",
    "            AND Status=\"complete\"\n",
    "        )\n",
    "        AND NOT EXISTS(\n",
    "            SELECT 1 FROM process_runs pr\n",
    "            WHERE pr.Location=lf.Location\n",
    "            AND Setup=\"MpM6\" \n",
    "            AND runAnyway=\"no\"\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "def create_gdf_from_markets(df):\n",
    "    \"\"\"Convert a DataFrame with 'marketLat' and 'marketLon' into a GeoDataFrame.\"\"\"\n",
    "    df[\"geometry\"] = df.apply(\n",
    "        lambda row: Point(row[\"marketLon\"], row[\"marketLat\"]), axis=1\n",
    "    )\n",
    "    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")  # Assuming WGS84\n",
    "\n",
    "\n",
    "def shpFromQuery(query):\n",
    "    df = pd.read_sql(query, engine)\n",
    "    df = df[df[\"marketLat\"].notnull()]\n",
    "    gdf = create_gdf_from_markets(df)\n",
    "    print(\"# markets:\", len(gdf))\n",
    "    return gdf\n",
    "\n",
    "\n",
    "market_centroids = shpFromQuery(query)\n",
    "\n",
    "market_centroids['marketDays'] = market_centroids['marketDays'].astype(str)\n",
    "market_centroids['comma_count'] = market_centroids['marketDays'].astype(str).str.count(',')\n",
    "market_centroids['marketDaysCount'] = market_centroids['comma_count']+1\n",
    "average = market_centroids['marketDaysCount'].mean()\n",
    "print(\"Number of market days on average: \",average)\n",
    "print(\"frequency of market days\",  market_centroids['marketDaysCount'].value_counts().sort_index())\n",
    "mkts_w_2_mktdays = market_centroids[market_centroids['comma_count']==1]\n",
    "\n",
    "# Split on comma and remove curly braces and whitespace\n",
    "mkts_w_2_mktdays[['mktday1', 'mktday2']] = (\n",
    "    mkts_w_2_mktdays['marketDays']\n",
    "    .str.strip('{}')                # remove curly braces\n",
    "    .str.replace(\"'\", \"\", regex=False)  # remove single quotes\n",
    "    .str.replace('\"', \"\", regex=False)  # remove double quotes\n",
    "    .str.split(',', expand=True)   # split into columns\n",
    "    .apply(lambda col: col.str.strip().astype(float))  # strip spaces and convert to float\n",
    ")\n",
    "\n",
    "mkts_w_2_mktdays['diff'] = abs(mkts_w_2_mktdays['mktday1']-mkts_w_2_mktdays['mktday2'])\n",
    "freq_table = mkts_w_2_mktdays['diff'].value_counts().sort_index()\n",
    "print(freq_table)\n",
    "\n",
    "\n",
    "\n",
    "# Load the shapefile\n",
    "gdf = gpd.read_file('C:\\\\Users\\\\tillmanv\\\\Downloads\\\\ETH_20250630.shp')\n",
    "\n",
    "# Ensure the GeoDataFrame has a projected CRS (in meters) for accurate area calculation\n",
    "# If it's in a geographic CRS (degrees), reproject it first, e.g., to UTM\n",
    "if gdf.crs.is_geographic:\n",
    "    gdf = gdf.to_crs(epsg=32633)  # Replace 32633 with the appropriate UTM zone EPSG code for your data\n",
    "\n",
    "# Calculate area in square meters\n",
    "gdf['area_sqm'] = gdf.geometry.area\n",
    "\n",
    "# Convert to hectares (1 ha = 10,000 sqm)\n",
    "gdf['area_ha'] = gdf['area_sqm'] / 10000\n",
    "\n",
    "# Calculate average area in hectares\n",
    "average_area_ha = gdf['area_ha'].mean()\n",
    "\n",
    "print(f\"Average size of shapes: {average_area_ha:.2f} hectares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table S3   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "query_tp = '''\n",
    "    SELECT Location FROM location_file lf \n",
    "    WHERE country =\"Ethiopia\"\n",
    "    AND false_positive=0\n",
    "'''\n",
    "\n",
    "query_fp = '''\n",
    "    SELECT Location FROM location_file lf \n",
    "    WHERE country =\"Ethiopia\"\n",
    "    AND false_positive=1\n",
    "'''\n",
    "\n",
    "query_tn = '''\n",
    "    SELECT Location FROM location_file lf \n",
    "    WHERE country =\"Ethiopia\"\n",
    "    AND EXISTS(\n",
    "        SELECT 1 FROM process_runs pr\n",
    "        WHERE lf.Location=pr.Location\n",
    "        AND Setup=\"MpM6\"\n",
    "        AND (runAnyway = 'no' OR (minStrictnessRank>20 AND runAnyway IS NULL) OR Status=\"failed\")\n",
    "    )\n",
    "    '''\n",
    "\n",
    "query_fn = '''\n",
    "    SELECT Location FROM location_file lf \n",
    "    WHERE country =\"Ethiopia\"\n",
    "    AND EXISTS(\n",
    "        SELECT 1 FROM process_runs pr\n",
    "        WHERE lf.Location=pr.Location\n",
    "        AND minStrictnessRank>20\n",
    "        AND runAnyway = 'yes'\n",
    "    )\n",
    "'''\n",
    "\n",
    "df_tp = pd.read_sql(query_tp, engine)\n",
    "df_fp = pd.read_sql(query_fp, engine)\n",
    "df_tn = pd.read_sql(query_tn, engine)\n",
    "df_fn = pd.read_sql(query_fn, engine)\n",
    "\n",
    "TP = len(df_tp)\n",
    "FP = len(df_fp)\n",
    "TN = len(df_tn)\n",
    "FN = len(df_fn)\n",
    "\n",
    "# Compute share metrics\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "fn_rate = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "\n",
    "print(f\"True positives: {len(df_tp)}\")\n",
    "print(f\"False positives: {len(df_fp)}\")\n",
    "print(f\"True negatives: {len(df_tn)}\")\n",
    "print(f\"False negatives: {len(df_fn)}\")\n",
    "print(f\"Share of true positives among positives: {len(df_tp) / (len(df_tp) + len(df_fp)):.1%}\")\n",
    "print(f\"Share of false negatives among marketplaces: {len(df_fn) / (len(df_tp) + len(df_fn)):.1%}\")\n",
    "\n",
    "# Processesing the signal data for a specific country by grouping into quantiles.\n",
    "# Locations with minStrictnessRank > 20 should still be treated as true positives in quantile-wise detection calculations if runAnyway=\"yes\" in the database.\n",
    "query = f'''\n",
    "SELECT\n",
    "    lf.Location,\n",
    "    lf.maxSignal,\n",
    "    lf.false_positive,\n",
    "    pr.minStrictnessRank,\n",
    "    pr.runAnyway\n",
    "FROM\n",
    "    location_file lf\n",
    "JOIN\n",
    "    process_runs pr ON lf.Location = pr.Location\n",
    "WHERE lf.country=\"{country}\"\n",
    "    AND maxSignal > 0\n",
    "    AND pr.Setup=\"MpM6\"\n",
    "    AND Status IN ('complete','failed')\n",
    "LIMIT 10000\n",
    "'''\n",
    "cnx = mysql.connector.connect(user='root', password='BMkjM8_)-tN8R33u', host='34.72.234.161', database='mai-database')\n",
    "cursor = cnx.cursor()\n",
    "cursor.execute(query)\n",
    "response = cursor.fetchall()\n",
    "cnx.close()\n",
    "cursor.close()\n",
    "\n",
    "# Creating a condition that checks if the query result is empty \n",
    "# if empty, it will print a warning message and exits the function to prevent further processing of nonexistent data.\n",
    "\n",
    "quantiles=10\n",
    "# Creating DataFrame\n",
    "df = pd.DataFrame(response, columns=['Location', 'maxSignal','false_positive', 'minStrictnessRank', 'runAnyway']).sort_values(by='maxSignal')#sorts dataframe by maxSignal in ascending order\n",
    "df['maxSignal'] = pd.to_numeric(df['maxSignal'])\n",
    "\n",
    "\n",
    "df['quantile'] = pd.qcut(df['maxSignal'], quantiles, labels=False, duplicates=\"drop\") # Divides maxSignal values into quantiles and assigns each row a quantile index.\n",
    "\n",
    "# Compute total candidate locations screened and locations where minStrictnessRank <= 20 and adds runAnyway\n",
    "total_locs_screened = df.shape[0]\n",
    "total_locs_min_rank = ((df['minStrictnessRank'] <= 20) & (df['false_positive'] != 1)).sum()\n",
    "total_locs_run_anyway = (df['runAnyway'] == \"yes\").sum()\n",
    "total_locs_false_pos = (df['false_positive'] == 1).sum()\n",
    "lambda x: ((x < 20) | (df.loc[x.index, 'runAnyway'] == \"yes\"))\n",
    "# Create a bar chart for the country\n",
    "\n",
    "# Create a combined figure with 2 subplots side-by-side\n",
    "fig, (ax_bar, ax_conf) = plt.subplots(1, 2, figsize=(12, 5), gridspec_kw={'width_ratios': [2, 1]})\n",
    "\n",
    "# === Bar Chart ===\n",
    "decile_summary = df.groupby('quantile').agg(\n",
    "    share_with_true_positive=('minStrictnessRank', lambda x: ((x < 20) &  (df.loc[x.index, 'false_positive'] != 1)).mean()),\n",
    "    share_with_false_negative=('runAnyway', lambda x: (x == \"yes\").mean()),\n",
    "    share_with_false_positive=('false_positive', lambda x: (x == 1).mean()),\n",
    "    min_maxSignal=('maxSignal', 'min')\n",
    ").reset_index()\n",
    "\n",
    "decile_summary['share_with_true_negative'] = 1 - decile_summary['share_with_true_positive'] - decile_summary['share_with_false_positive'] - decile_summary['share_with_false_negative']\n",
    "decile_summary['quantile'] = decile_summary['quantile'] + 1\n",
    "\n",
    "bars1 = ax_bar.bar(decile_summary['quantile'].astype(str), decile_summary['share_with_true_positive'], label='True positive', color=color3)\n",
    "bars2 = ax_bar.bar(decile_summary['quantile'].astype(str), decile_summary['share_with_false_negative'], bottom=decile_summary['share_with_true_positive'], label='False negative', color=color3, alpha=0.8)\n",
    "bars3 = ax_bar.bar(decile_summary['quantile'].astype(str), decile_summary['share_with_false_positive'], bottom=decile_summary['share_with_true_positive'] + decile_summary['share_with_false_negative'], label='False positive', color=color1, alpha=0.8)\n",
    "bars4 = ax_bar.bar(decile_summary['quantile'].astype(str), decile_summary['share_with_true_negative'], bottom=decile_summary['share_with_true_positive'] + decile_summary['share_with_false_negative'] + decile_summary['share_with_false_positive'], label='True negative', color=color1)\n",
    "\n",
    "ax_bar.set_xlabel(\"Decile of Sentinel-2 signal strength (high → low)\")\n",
    "ax_bar.set_ylabel(\"Share of candidate locations\")\n",
    "ax_bar.set_ylim(0, 1)\n",
    "ax_bar.invert_xaxis()\n",
    "ax_bar.spines[\"top\"].set_visible(False)\n",
    "ax_bar.spines[\"right\"].set_visible(False)\n",
    "handles, labels = ax_bar.get_legend_handles_labels()\n",
    "ax_bar.legend(handles[::-1], labels[::-1],loc=\"upper center\")\n",
    "\n",
    "\n",
    "# === Confusion Matrix ===\n",
    "conf_values = [['True positive', 'False positive'], ['False negative', 'True negative']]\n",
    "conf_counts = [[TP, FP], [FN, TN]]  # Example counts, replace with your real numbers\n",
    "conf_colors = [[color3,to_rgba(color1, alpha=0.8)], [to_rgba(color3, alpha=0.8), color1]]\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        rect = patches.Rectangle((j, i), 1, 1, facecolor=conf_colors[i][j])\n",
    "        ax_conf.add_patch(rect)\n",
    "        ax_conf.text(j + 0.5, i + 0.5,\n",
    "                     f\"{conf_values[i][j]}\\n{conf_counts[i][j]:,}\",\n",
    "                     ha='center', va='center',  color='black')\n",
    "\n",
    "ax_conf.set_xticks([0.5, 1.5])\n",
    "ax_conf.set_xticklabels(['Actual\\nmarketplace', 'Actual\\nno marketplace'])\n",
    "ax_conf.set_yticks([0.5, 1.5])\n",
    "ax_conf.set_yticklabels(['Predicted\\nmarketplace', 'Predicted\\nno marketplace'])\n",
    "ax_conf.set_xlim(0, 2)\n",
    "ax_conf.set_ylim(0, 2)\n",
    "ax_conf.invert_yaxis()\n",
    "ax_conf.set_aspect('equal')\n",
    "ax_conf.tick_params(left=False, bottom=False)\n",
    "\n",
    "fig.text(0.01, 0.98, \"A\", fontsize=12, fontweight=\"bold\", ha=\"left\", va=\"top\")\n",
    "fig.text(0.6, 0.98, \"B\", fontsize=12, fontweight=\"bold\", ha=\"left\", va=\"top\")\n",
    "\n",
    "for label in ax_conf.get_xticklabels() + ax_conf.get_yticklabels():\n",
    "    label.set_multialignment('center')\n",
    "\n",
    "# Metrics below the figure\n",
    "ax_conf.text(0.5, 2.4, f\"Share of true positives among predicted positives (Precision): {precision:.1%}\", ha='center', fontsize=10)\n",
    "ax_conf.text(0.5, 2.55, f\"Share of false negatives among marketplaces: {fn_rate:.1%}\", ha='center', fontsize=10)\n",
    "ax_conf.spines[\"top\"].set_visible(False)\n",
    "ax_conf.spines[\"right\"].set_visible(False)\n",
    "ax_conf.spines[\"bottom\"].set_visible(False)\n",
    "ax_conf.spines[\"left\"].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# markets:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(gdf))\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gdf\n\u001b[1;32m---> 38\u001b[0m kenya_df \u001b[38;5;241m=\u001b[39m \u001b[43mshpFromQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKenya\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m mozambique_df \u001b[38;5;241m=\u001b[39m shpFromQuery(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMozambique\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m malawi_df \u001b[38;5;241m=\u001b[39m shpFromQuery(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmalawi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 32\u001b[0m, in \u001b[0;36mshpFromQuery\u001b[1;34m(country)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshpFromQuery\u001b[39m(country):\n\u001b[0;32m     27\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124m       SELECT lat, lon FROM `mai-database`.`location_file` lf\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124m        WHERE country=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124m        AND validation=1\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124m               \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 32\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(query, \u001b[43mengine\u001b[49m)\n\u001b[0;32m     33\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull()]\n\u001b[0;32m     34\u001b[0m     gdf \u001b[38;5;241m=\u001b[39m create_gdf_from_markets(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from PIL import Image\n",
    "import PIL  # Needed if you're using PIL.Image explicitly\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "def create_gdf_from_markets(df):\n",
    "    \"\"\"Convert a DataFrame with 'marketLat' and 'marketLon' into a GeoDataFrame.\"\"\"\n",
    "    df[\"geometry\"] = df.apply(\n",
    "        lambda row: Point(row[\"lon\"], row[\"lat\"]), axis=1\n",
    "    )\n",
    "    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")  # Assuming WGS84\n",
    "\n",
    "\n",
    "def shpFromQuery(country):\n",
    "    query = f\"\"\"\n",
    "       SELECT lat, lon FROM `mai-database`.`location_file` lf\n",
    "        WHERE country=\"{country}\"\n",
    "        AND validation=1\n",
    "               \"\"\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    df = df[df[\"lat\"].notnull()]\n",
    "    gdf = create_gdf_from_markets(df)\n",
    "    print(\"# markets:\", len(gdf))\n",
    "    return gdf\n",
    "\n",
    "kenya_df = shpFromQuery('Kenya')\n",
    "mozambique_df = shpFromQuery('Mozambique')\n",
    "malawi_df = shpFromQuery('malawi')\n",
    "display(malawi_df)\n",
    "\n",
    "\n",
    "def scale_bar(ax, length=None, location=(0.5, 0.05), linewidth=3, unit=\"km\"):\n",
    "    \"\"\"\n",
    "    ax is the axes to draw the scalebar on.\n",
    "    length is the length of the scalebar in km.\n",
    "    location is center of the scalebar in axis coordinates.\n",
    "    (ie. 0.5 is the middle of the plot)\n",
    "    linewidth is the thickness of the scalebar.\n",
    "    \"\"\"\n",
    "    #Get the limits of the axis in lat long\n",
    "    llx0, llx1, lly0, lly1 = ax.get_extent(ccrs.PlateCarree())\n",
    "    #Make tmc horizontally centred on the middle of the map,\n",
    "    #vertically at scale bar location\n",
    "    sbllx = (llx1 + llx0) / 2\n",
    "    sblly = lly0 + (lly1 - lly0) * location[1]\n",
    "    tmc = ccrs.TransverseMercator(sbllx, sblly)\n",
    "    #Get the extent of the plotted area in coordinates in metres\n",
    "    x0, x1, y0, y1 = ax.get_extent(tmc)\n",
    "    #Turn the specified scalebar location into coordinates in metres\n",
    "    sbx = x0 + (x1 - x0) * location[0]\n",
    "    sby = y0 + (y1 - y0) * location[1]\n",
    "\n",
    "    #Calculate a scale bar length if none has been given\n",
    "    #(Theres probably a more pythonic way of rounding the number but this works)\n",
    "    if not length: \n",
    "        length = (x1 - x0) / 5000 #in km\n",
    "        ndim = int(np.floor(np.log10(length))) #number of digits in number\n",
    "        length = round(length, -ndim) #round to 1sf\n",
    "        #Returns numbers starting with the list\n",
    "        def scale_number(x):\n",
    "            if str(x)[0] in ['1', '2', '5']: return int(x)        \n",
    "            else: return scale_number(x - 10 ** ndim)\n",
    "        length = scale_number(length) \n",
    "\n",
    "    #Generate the x coordinate for the ends of the scalebar\n",
    "    bar_xs = [sbx, sbx + 2*length * 500]\n",
    "    #Plot the scalebar\n",
    "    ax.plot(bar_xs, [sby, sby], transform=tmc, color='k', linewidth=linewidth)\n",
    "    #Plot the scalebar label\n",
    "    ax.text(sbx+ length * 500, sby, str(length) + f' {unit}', transform=tmc,\n",
    "            horizontalalignment='center', verticalalignment='bottom', fontsize=20)\n",
    "\n",
    "def plot_map(ax, df, country, color):\n",
    "    \"\"\"Generate a map with specified coordinates on the given axes.\"\"\"\n",
    "    clon = list(df['lon'])\n",
    "    clat = list(df['lat'])\n",
    "    minlon = min(clon)\n",
    "    maxlon = max(clon)\n",
    "    minlat = min(clat)\n",
    "    maxlat = max(clat)\n",
    "    central_lon = np.mean([minlon, maxlon])\n",
    "    central_lat = np.mean([minlat, maxlat])\n",
    "    \n",
    "    # Main map\n",
    "    extent_values = [maxlon - minlon, maxlat - minlat]\n",
    "    larger_extent = max(extent_values)\n",
    "    larger_extent_index = np.argmax(extent_values)\n",
    "    add = extent_values[larger_extent_index]/20\n",
    "    ext_lon = ((central_lon  -add- larger_extent/2), (central_lon  +add+ larger_extent/2))\n",
    "    ext_lat = ((central_lat  -add- larger_extent/2), (central_lat  +add+ larger_extent/2))\n",
    "    print('pre',ext_lon,add)\n",
    "    #ext_lon = ((central_lon  - larger_extent/2)*0.995, (central_lon  + larger_extent/2)*1.005)\n",
    "    #print('post',ext_lon)\n",
    "    if country==\"Malawi\":\n",
    "        ax.set_extent([ext_lon[0]-.5, ext_lon[1]-.5, ext_lat[0], ext_lat[1]], crs=ccrs.PlateCarree())\n",
    "    else:\n",
    "        ax.set_extent([ext_lon[0], ext_lon[1], ext_lat[0], ext_lat[1]], crs=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle='-')\n",
    "    #img = PIL.Image.open('forFigures/eo_base_2020_clean_geo.tif')\n",
    "    #img_extent = (-180, 180, -90, 90)\n",
    "    #ax.imshow(img, origin='upper', extent=img_extent, transform=ccrs.PlateCarree(), alpha=.3)\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
    "    ax.add_feature(cfeature.OCEAN)\n",
    "    if country==\"Kenya\":\n",
    "        scale_bar(ax, 50,(0.05,0.05))\n",
    "    elif country==\"Mozambique\":\n",
    "        scale_bar(ax, 200,(0.05,0.05))\n",
    "    elif country==\"Malawi\":\n",
    "        scale_bar(ax, 100,(0.05,0.05))\n",
    "        \n",
    "    ax.set_title(country, y=1.0, pad=5, fontsize = 24)\n",
    "    \n",
    "    # Plotting points\n",
    "    #if country==\"Kenya\":\n",
    "    #    gdf = gpd.read_file('forFigures/siaya_villages_bounding.shp')\n",
    "    #    gdf.plot(ax=ax, color= maincolors[2], edgecolor='none', alpha=0.3)\n",
    "    #    ax.scatter(siaya['mkt_lon'], siaya['mkt_lat'], color = 'gray', label='Points', transform=ccrs.PlateCarree(), marker='s', s=100)\n",
    "    ax.scatter(df['lon'], df['lat'], color = color, label='Points', transform=ccrs.PlateCarree())\n",
    "    # Inset map\n",
    "    \n",
    "    ax_inset = ax.inset_axes([0, 0.6, 0.4, 0.4], \n",
    "                             projection=ccrs.Orthographic(central_longitude=central_lon, \n",
    "                                                          central_latitude=central_lat))\n",
    "    ax_inset.set_extent([central_lon - 15, central_lon + 15, central_lat - 15, central_lat + 15], crs=ccrs.PlateCarree())\n",
    "    ax_inset.add_feature(cfeature.OCEAN)\n",
    "    ax_inset.add_feature(cfeature.LAND, facecolor='white')\n",
    "    ax_inset.add_feature(cfeature.COASTLINE)\n",
    "    ax_inset.add_feature(cfeature.BORDERS, linestyle='-')\n",
    "    rectangle = Rectangle((ext_lon[0], ext_lat[0]), ext_lon[1] - ext_lon[0], ext_lat[1] - ext_lat[0], \n",
    "                          linewidth=1, edgecolor=color, facecolor=color, alpha=0.8,\n",
    "                          transform=ccrs.PlateCarree())\n",
    "    ax_inset.add_patch(rectangle)\n",
    "\n",
    "dfs = [kenya_df, malawi_df, mozambique_df]\n",
    "maincolors = ['#2A9D8F','#E9C46A','#E76F51']\n",
    "country_names = ['Kenya', 'Malawi', 'Mozambique']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), subplot_kw={'projection': ccrs.PlateCarree()}, gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "\n",
    "for ax,df, country, color in zip(axes, dfs, country_names, maincolors):\n",
    "    plot_map(ax, df, country, color)\n",
    "\n",
    "plt.savefig(f\"FigureS4.png\", bbox_inches='tight', pad_inches=0, dpi=300)    \n",
    "plt.show()\n",
    "plt.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure S2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_tp = '''\n",
    "    SELECT Location, lat, lon FROM location_file lf \n",
    "    WHERE country =\"Ethiopia\"\n",
    "    AND false_positive=0\n",
    "'''\n",
    "\n",
    "query_fp = '''\n",
    "    SELECT Location, lat, lon FROM location_file lf \n",
    "    WHERE country =\"Ethiopia\"\n",
    "    AND false_positive=1\n",
    "'''\n",
    "\n",
    "query_tn = '''\n",
    "    SELECT Location, lat, lon FROM location_file lf \n",
    "    WHERE country =\"Ethiopia\"\n",
    "    AND EXISTS(\n",
    "        SELECT 1 FROM process_runs pr\n",
    "        WHERE lf.Location=pr.Location\n",
    "        AND Setup=\"MpM6\"\n",
    "        AND (runAnyway = 'no' OR (minStrictnessRank>20 AND runAnyway IS NULL) OR Status=\"failed\")\n",
    "    )\n",
    "    '''\n",
    "\n",
    "query_fn = '''\n",
    "    SELECT Location, lat, lon FROM location_file lf \n",
    "    WHERE country =\"Ethiopia\"\n",
    "    AND EXISTS(\n",
    "        SELECT 1 FROM process_runs pr\n",
    "        WHERE lf.Location=pr.Location\n",
    "        AND minStrictnessRank>20\n",
    "        AND runAnyway = 'yes'\n",
    "    )\n",
    "'''\n",
    "\n",
    "df_tp = pd.read_sql(query_tp, engine)\n",
    "df_tp['market']=1\n",
    "df_fp = pd.read_sql(query_fp, engine)\n",
    "df_fp['market']=0\n",
    "df_tn = pd.read_sql(query_tn, engine)\n",
    "df_tn['market']=0\n",
    "df_fn = pd.read_sql(query_fn, engine)\n",
    "df_fn['market']=1\n",
    "\n",
    "df_all = pd.concat([df_tp, df_fp, df_tn, df_fn], ignore_index=True)\n",
    "geometry = [Point(xy) for xy in zip(df_all['lon'], df_all['lat'])]\n",
    "\n",
    "# Create GeoDataFrame, specifying coordinate reference system (CRS)\n",
    "df_all = gpd.GeoDataFrame(df_all, geometry=geometry, crs=\"EPSG:4326\")  # WGS84 lat/lon\n",
    "display(df_all)\n",
    "\n",
    "# )  # Create a figure with size 16x16 inches\n",
    "def plot_population_and_markets_add(ax):\n",
    "    # Read the raster data\n",
    "    # Plot the market centroids (assuming market_centroids is already a GeoDataFrame with the 'geometry' column)\n",
    "\n",
    "    df_all[df_all['market'] == 0].plot(\n",
    "        ax=ax, facecolor=\"none\", edgecolor=\"0.5\", marker=\"o\", markersize=8, label=\"Candidate locations without confirmed marketplaces\", alpha=1\n",
    "    )\n",
    "    df_all[df_all['market'] == 1].plot(\n",
    "        ax=ax, facecolor=\"none\", edgecolor=color3, marker=\"o\", markersize=8, label=\"Detected marketplaces\", alpha=1\n",
    "    )\n",
    "    # Plot the Ethiopia boundaries\n",
    "    eth_boundaries.plot(ax=ax, color=\"none\", edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "\n",
    "    legend_title = mpatches.Patch(\n",
    "        facecolor='none',  # Transparent fill\n",
    "        edgecolor='none',  # No border\n",
    "        label=\"People per km²:\"  # Leading spaces to align\n",
    "    )\n",
    "\n",
    "    candidate_legend = mlines.Line2D(\n",
    "        [],\n",
    "        [],\n",
    "        color=\"gray\",  # or any color you like\n",
    "        marker=\"o\",\n",
    "        markerfacecolor=\"none\",\n",
    "        markeredgecolor=\"gray\",\n",
    "        linestyle=\"none\",\n",
    "        markersize=7,\n",
    "        label=\"Candidate locations without detected marketplaces\",\n",
    "    )\n",
    "\n",
    "    market_legend = mlines.Line2D(\n",
    "        [],\n",
    "        [],\n",
    "        color=color3,\n",
    "        markerfacecolor=\"none\",\n",
    "        linestyle=\"none\",\n",
    "        markeredgecolor=color3,\n",
    "        marker=\"o\",\n",
    "        markersize=7,\n",
    "        label=\"Detected marketplaces\",\n",
    "    )\n",
    "\n",
    "    #leg.get_title().set_multialignment(\"center\")\n",
    "    \n",
    "    legend1 = ax.legend(handles=[candidate_legend,market_legend], loc='upper left', frameon=False, bbox_to_anchor=(0.5, 1), borderaxespad=0, fontsize=15)\n",
    "    ax.add_artist(legend1)\n",
    "\n",
    "    fontprops = fm.FontProperties(size=12)\n",
    "    scalebar = AnchoredSizeBar(\n",
    "        ax.transData,\n",
    "        longitude_degrees,\n",
    "        f\"{km} km\",\n",
    "        \"lower left\",\n",
    "        pad=0,\n",
    "        color=\"black\",\n",
    "        frameon=False,\n",
    "        size_vertical=0.05,\n",
    "        fontproperties=fontprops,\n",
    "    )\n",
    "\n",
    "    ax.add_artist(scalebar)\n",
    "\n",
    "    # Set the minimum limit for the y-axis to this latitude and an arbitrary max limit\n",
    "    ax.set_ylim(bottom=eth_boundaries.total_bounds[1], top=eth_boundaries.total_bounds[3])\n",
    "    ax.set_xlim(left=eth_boundaries.total_bounds[0], right=eth_boundaries.total_bounds[2]+0.5)\n",
    "\n",
    "    # Add labels and display the map\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "    ax.axis(\"off\")\n",
    " \n",
    "    plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 12), dpi=300)\n",
    "plot_population_and_markets_add(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load EE FeatureCollections\n",
    "grid_w_pop = ee.FeatureCollection(f\"projects/planetupload/assets/cleanedLocs/{country}_ringsghsl\")\n",
    "grid_w_pop_without_addis = ee.FeatureCollection(f\"projects/planetupload/assets/cleanedLocs/{country}_ringsghsl_withoutaddis\")\n",
    "grid_w_pop_census = ee.FeatureCollection(f\"projects/planetupload/assets/cleanedLocs/{country}_censusMarkets_ringsghsl\")\n",
    "grid_w_pop_without_addis_census = ee.FeatureCollection(f\"projects/planetupload/assets/cleanedLocs/{country}_censusMarkets_ringsghsl_withoutaddis\")\n",
    "\n",
    "# Convert to GeoDataFrames\n",
    "df_b = geemap.ee_to_gdf(grid_w_pop)\n",
    "df_b_noaddis = geemap.ee_to_gdf(grid_w_pop_without_addis)\n",
    "df_b_census = geemap.ee_to_gdf(grid_w_pop_census)\n",
    "df_b_noaddis_census = geemap.ee_to_gdf(grid_w_pop_without_addis_census)\n",
    "\n",
    "# Merge on 'radius'\n",
    "df_b = df_b.merge(df_b_noaddis[['radius', 'population']], on='radius', how='left', suffixes=('', '_noaddis'))\n",
    "df_b = df_b.merge(df_b_census[['radius', 'population']], on='radius', how='left', suffixes=('', '_census'))\n",
    "df_b = df_b.merge(df_b_noaddis_census[['radius', 'population']], on='radius', how='left', suffixes=('', '_noaddis_census'))\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_b.rename(columns={\n",
    "    'population': 'population_all',\n",
    "    'population_noaddis': 'population_without_addis',\n",
    "    'population_census': 'population_census',\n",
    "    'population_noaddis_census': 'population_census_without_addis'\n",
    "}, inplace=True)\n",
    "\n",
    "# Calculate population shares (%)\n",
    "total_population = 109_628_500\n",
    "total_population_noaddis = 103_971_800\n",
    "df_b['pop_share_all'] = 100 * df_b['population_all'] / total_population\n",
    "df_b['pop_share_without_addis'] = 100 * df_b['population_without_addis'] / total_population_noaddis\n",
    "df_b['pop_share_census'] = 100 * df_b['population_census'] / total_population\n",
    "df_b['pop_share_census_without_addis'] = 100 * df_b['population_census_without_addis'] / total_population_noaddis\n",
    "\n",
    "# Filter for 1km radius\n",
    "df_1km = df_b[df_b['radius'] == 1000].copy()\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Load data for line chart\n",
    "city_geom = ee.FeatureCollection(\"projects/ethiopia-candidate-locs/assets/cityMask\").first().geometry()\n",
    "census_markets = ee.FeatureCollection(\n",
    "    f\"projects/planetupload/assets/cleanedLocs/{country}_censusMarkets_popProximity_withoutAddis\"\n",
    ").filter(\n",
    "    ee.Filter.intersects('.geo', city_geom).Not()\n",
    ")\n",
    "mai_markets = ee.FeatureCollection(f\"projects/planetupload/assets/cleanedLocs/{country}_maiMarkets_popProximity_withoutAddis\")\n",
    "\n",
    "df_census = geemap.ee_to_gdf(census_markets)\n",
    "df_mai = geemap.ee_to_gdf(mai_markets)\n",
    "\n",
    "# Extract population columns within 500m\n",
    "pop_cols = sorted([col for col in df_census.columns if col.startswith('pop_')], key=lambda x: int(x.split('_')[1].replace('m', '')))\n",
    "pop_cols = [col for col in pop_cols if int(col.split('_')[1].replace('m', '')) <= 500]\n",
    "distances = [int(col.split('_')[1].replace('m', '')) for col in pop_cols]\n",
    "\n",
    "# Calculate shares under threshold\n",
    "threshold = 100\n",
    "shares_census = 100* (df_census[pop_cols] < threshold).sum() / len(df_census)\n",
    "shares_mai = 100*(df_mai[pop_cols] < threshold).sum() / len(df_mai)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# PLOTTING: Side-by-side plots\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "## --- A. Bar Chart ---\n",
    "x = [0, 1]\n",
    "width = 0.35\n",
    "\n",
    "# Bars: actual data (hidden from legend)\n",
    "ax1.bar(x[0], df_1km['pop_share_without_addis'].values[0], color=\"none\", edgecolor=color3, linewidth=1.5, linestyle=\"--\", label=\"_nolegend_\")\n",
    "ax1.bar(x[0], df_1km['pop_share_all'].values[0], color=\"none\", edgecolor=color3, linewidth=1.5, label=\"_nolegend_\")\n",
    "ax1.bar(x[1], df_1km['pop_share_census_without_addis'].values[0], color=\"none\", edgecolor=color1, linewidth=1.5, linestyle=\"--\", label=\"_nolegend_\")\n",
    "ax1.bar(x[1], df_1km['pop_share_census'].values[0], color=\"none\", edgecolor=color1, linewidth=1.5, label=\"_nolegend_\")\n",
    "\n",
    "# Dummy bars for legend\n",
    "ax1.bar(0, 0, color=\"none\", edgecolor=\"gray\", linestyle=\"-\", linewidth=1.5, label=\"Population\")\n",
    "ax1.bar(0, 0, color=\"none\", edgecolor=\"gray\", linestyle=\"--\", linewidth=1.5, label=\"Population \\nexcl. Addis Ababa\")\n",
    "\n",
    "# Formatting\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(['Detected marketplaces \\n n = 1,712', '2007 census marketplaces \\n n = 2,670'])\n",
    "ax1.set_ylabel('Population share within 1 km (%)')\n",
    "ax1.set_yticks([0, 3, 6, 9, 12, 15, 18])\n",
    "ax1.set_ylim(0, 19)\n",
    "ax1.legend(frameon=False)\n",
    "ax1.spines[\"top\"].set_visible(False)\n",
    "ax1.spines[\"right\"].set_visible(False)\n",
    "ax1.grid(False)\n",
    "\n",
    "# Label\n",
    "ax1.text(-0.15, 1.02, \"A\", transform=ax1.transAxes, fontsize=12, fontweight=\"bold\", va=\"top\", ha=\"left\")\n",
    "\n",
    "## --- B. Line Chart ---\n",
    "ax2.plot(distances, shares_census, linestyle='solid', color=color1,linewidth=1.5)\n",
    "ax2.plot(distances, shares_mai, linestyle='solid', color=color3,linewidth=1.5)\n",
    "\n",
    "# Annotation\n",
    "ax2.text(1, 0.3, \"2007 census marketplaces\", color=color1, fontsize=12, transform=ax2.transAxes, ha='right')\n",
    "ax2.text(1, 0.07, \"Detected marketplaces\", color=color3, fontsize=12, transform=ax2.transAxes, ha='right')\n",
    "\n",
    "# Formatting\n",
    "ax2.set_xlabel('Distance band (m)')\n",
    "ax2.set_ylabel('Share of markets with <100 people (%)')\n",
    "ax2.set_xticks(distances)\n",
    "ax2.set_xlim([100, 500])\n",
    "ax2.set_ylim([0, 65])\n",
    "ax2.spines[\"top\"].set_visible(False)\n",
    "ax2.spines[\"right\"].set_visible(False)\n",
    "ax2.grid(False)\n",
    "\n",
    "# Label\n",
    "ax2.text(-0.15, 1.02, \"B\", transform=ax2.transAxes, fontsize=12, fontweight=\"bold\", va=\"top\", ha=\"left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
