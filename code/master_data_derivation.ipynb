{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook provides a step-by-step example of our processing pipeline for a single candidate location in Ethiopia, from acquiring imagery to creating the final market activity plot.\n",
    "\n",
    "Note that we are unable to provide the original Planet imagery, but we are able to provide all intermediate products and analyses subsequent to the initial imagery processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Setup Instructions\n",
    "\n",
    "This notebook requires both Python and Node.js dependencies to run properly. Follow these steps to set up your environment:\n",
    "\n",
    "## Python Environment Setup\n",
    "\n",
    "#### 1. Create and activate a virtual environment (recommended):\n",
    "```bash\n",
    "# Create virtual environment\n",
    "python3 -m venv .venv\n",
    "\n",
    "# Activate virtual environment\n",
    "# On macOS/Linux:\n",
    "source .venv/bin/activate\n",
    "# On Windows:\n",
    "# .venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "#### 2. Install Python dependencies:\n",
    "```bash\n",
    "pip install --upgrade pip\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "The `requirements.txt` file includes all necessary packages.\n",
    "\n",
    "## Node and ee-runner Setup\n",
    "\n",
    "#### 1. Install Node.js (version 18+ required, 20.x recommended):\n",
    "- Visit [nodejs.org](https://nodejs.org/) and install Node.js version 20.x\n",
    "- Or use a version manager like nvm:\n",
    "```bash\n",
    "# Using nvm (recommended)\n",
    "nvm install 20\n",
    "nvm use 20\n",
    "```\n",
    "\n",
    "#### 2. Install ee-runner:\n",
    "```bash\n",
    "# Run this command in the project root directory\n",
    "npm install\n",
    "```\n",
    "\n",
    "This installs `@pdingus/ee-runner` locally, which is required for executing Google Earth Engine scripts.\n",
    "\n",
    "**Note:** The notebook automatically detects the Node.js and ee-runner paths, so you don't need to manually configure paths.\n",
    "\n",
    "## Earth Engine Setup\n",
    "\n",
    "This is required for the notebook to work with Google Earth Engine scripts.\n",
    "\n",
    "```bash\n",
    "# Install Earth Engine API (should already be in requirements.txt)\n",
    "pip install earthengine-api\n",
    "\n",
    "# Authenticate with Earth Engine\n",
    "earthengine authenticate\n",
    "\n",
    "# Set your Earth Engine project (replace with your project ID)\n",
    "earthengine set_project \"your-project-id\"\n",
    "```\n",
    "\n",
    "The gcloud CLI is required for authenticating ee-runner, which can be accessed here: [https://cloud.google.com/sdk/docs/install](https://cloud.google.com/sdk/docs/install). After installing, set project:\n",
    "\n",
    "```bash\n",
    "# Set gcloud project\n",
    "gcloud config set project your-project-name\n",
    "```\n",
    "\n",
    "## Optional: Planet Labs API (for imagery download):\n",
    "- Sign up for a Planet Labs account\n",
    "- Obtain an API key from your Planet account dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import folium\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Node.js at: /Users/pauldingus/.nvm/versions/node/v18.20.8/bin/node\n",
      "Node.js version: v18.20.8\n",
      "Node.js version is compatible\n",
      "Found ee-runner at: /Users/pauldingus/Dropbox/mai_shared/Submissions/MktAct/NatureComm/ReplicationPackage/node_modules/.bin/ee-runner\n",
      "Project root: /Users/pauldingus/Dropbox/mai_shared/Submissions/MktAct/NatureComm/ReplicationPackage\n"
     ]
    }
   ],
   "source": [
    "loc = \"lon38_5671lat9_2948\"\n",
    "locGroup = \"79_Ethiopia\"\n",
    "bucket = \"p79ethiopia65\"\n",
    "country=\"Ethiopia\"\n",
    "GEEproject=\"p155mali8\"\n",
    "\n",
    "# Get the current working directory (project root)\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "# If we're in the code subdirectory, go up one level to project root\n",
    "if current_dir.endswith('/code'):\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "repl_pkg_path = project_root\n",
    "\n",
    "# Dynamically find Node.js path\n",
    "try:\n",
    "    nodePath = subprocess.check_output([\"which\", \"node\"], text=True).strip()\n",
    "    \n",
    "    # Check Node.js version\n",
    "    node_version = subprocess.check_output([nodePath, \"--version\"], text=True).strip()\n",
    "    major_version = int(node_version.split('.')[0][1:])  # Remove 'v' and get major version\n",
    "    \n",
    "    print(f\"Found Node.js at: {nodePath}\")\n",
    "    print(f\"Node.js version: {node_version}\")\n",
    "    \n",
    "    if major_version < 18:\n",
    "        print(f\"Warning: Node.js version {node_version} is quite old. Consider upgrading to v20.x for best compatibility.\")\n",
    "    elif major_version >= 18:\n",
    "        print(\"Node.js version is compatible\")\n",
    "        \n",
    "except subprocess.CalledProcessError:\n",
    "    raise RuntimeError(\"Node.js not found. Please install Node.js version 20.x\")\n",
    "\n",
    "# Find ee-runner in local node_modules\n",
    "eerunnerPath = os.path.join(project_root, \"node_modules\", \".bin\", \"ee-runner\")\n",
    "if not os.path.exists(eerunnerPath):\n",
    "    raise RuntimeError(f\"ee-runner not found at {eerunnerPath}. Please run 'npm install' in the project root directory.\")\n",
    "\n",
    "print(f\"Found ee-runner at: {eerunnerPath}\")\n",
    "print(f\"Project root: {repl_pkg_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GEE code in the following cell takes as inputs the outlines of the candidate location and the downloaded imagery to produce a .tif file where each band represents the intensity of apperance differences on average across the images in the sample by day-of-week, against their respective reference composites. Running this code requires access to the proprietary imagery as well as a GEE account. We therefore provide the output of the code and visualize it in a subsequent cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Download Imagery\n",
    "\n",
    "This notebook demonstrates the satellite imagery download functionality. The system downloads satellite imagery from Planet Labs to a Google Cloud Storage bucket for subsequent analysis.\n",
    "\n",
    "The download system operates in three modes based on provided credentials:\n",
    "\n",
    "1. **Structure Overview** (No credentials) - Shows the complete system architecture and API request structure\n",
    "2. **Preview Mode** (API key only) - Connects to Planet API to analyze available imagery \n",
    "3. **Full Download** (API key + bucket) - Actually downloads and processes satellite imagery\n",
    "\n",
    "This demonstration is designed to verify the system works correctly. By default, it runs in Structure Overview mode (no credentials required), but you can optionally provide credentials to test the other modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "import os\n",
    "from data_derivation.download_imagery import downloader\n",
    "\n",
    "# Demonstration parameters\n",
    "location = \"lon38_5671lat9_2948\" # Unique identifier for the location of interest\n",
    "location_group = \"79_Ethiopia\" # Organizational parameter used for structureing our data\n",
    "end_date = \"2024-12-31\"\n",
    "max_cloud_cover = 30\n",
    "\n",
    "# Optional credentials (leave as None for structure overview mode)\n",
    "planet_api_key = None  # Replace with your Planet API key to test preview mode\n",
    "gcs_bucket = None      # Replace with your GCS bucket name to test download mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the download demonstration\n",
    "try:\n",
    "    result = downloader(\n",
    "        loc=location,\n",
    "        locGroup=location_group,\n",
    "        endDate=end_date,\n",
    "        maxCloudCover=max_cloud_cover,\n",
    "        planet_api_key=planet_api_key,\n",
    "        gcs_bucket=gcs_bucket\n",
    "    )\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nException occurred: {e}\")\n",
    "    print(\"This may be expected if using invalid credentials for demonstration purposes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create Difference Image Using Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running script: ./data_derivation/01_prep_torun.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the input file\n",
    "file_path = f\"./data_derivation/01_prep.txt\"\n",
    "\n",
    "# Read the content of the input file\n",
    "with open(file_path, \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Replace placeholders in the file content with actual variable values\n",
    "content = (content.replace(\"INSERT_LOC_HERE\", loc)\n",
    "                  .replace(\"INSERT_LOC_GROUP_HERE\", locGroup)\n",
    "                  .replace(\"INSERT_BUCKET_HERE\", bucket)\n",
    "                  .replace(\"INSERT_COUNTRY_HERE\", country))\n",
    "\n",
    "# Define the path for the new file with \"_torun\" suffix\n",
    "new_file_path = file_path.replace(\".txt\", \"_torun.txt\")\n",
    "\n",
    "# Write the updated content to the new file\n",
    "with open(new_file_path, \"w\") as new_file:\n",
    "    new_file.write(content)\n",
    "\n",
    "# Execute the updated script using Node.js and the ee-runner tool\n",
    "subprocess.call([\n",
    "    nodePath,                # Path to the Node.js executable\n",
    "    eerunnerPath,            # Path to the ee-runner script\n",
    "    new_file_path,           # Path to the updated script file\n",
    "    f\"--project={GEEproject}\"  # Specify the GEE project as a command-line argument\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RasterioIOError",
     "evalue": "../datasets/intermediate_outputs/lon38_5671lat9_2948_diffImg.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mrasterio/_base.pyx:308\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_base.pyx:219\u001b[0m, in \u001b[0;36mrasterio._base.open_dataset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:221\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: ../datasets/intermediate_outputs/lon38_5671lat9_2948_diffImg.tif: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m diffImg_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_diffImg.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Open the difference image using rasterio\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mrasterio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiffImg_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Extract band names and image bounds\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     band_names \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mdescriptions\n\u001b[1;32m      8\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mbounds\n",
      "File \u001b[0;32m~/Dropbox/mai_shared/Submissions/MktAct/NatureComm/ReplicationPackage/.venv/lib/python3.9/site-packages/rasterio/env.py:451\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    448\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/mai_shared/Submissions/MktAct/NatureComm/ReplicationPackage/.venv/lib/python3.9/site-packages/rasterio/__init__.py:304\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m path \u001b[38;5;241m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    306\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m get_writer_for_path(path, driver\u001b[38;5;241m=\u001b[39mdriver)(\n\u001b[1;32m    307\u001b[0m         path, mode, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    308\u001b[0m     )\n",
      "File \u001b[0;32mrasterio/_base.pyx:310\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: ../datasets/intermediate_outputs/lon38_5671lat9_2948_diffImg.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Define the path to the difference image file\n",
    "diffImg_path = os.path.join(\"..\", \"datasets\", \"intermediate_outputs\", f\"{loc}_diffImg.tif\")\n",
    "\n",
    "# Open the difference image using rasterio\n",
    "with rasterio.open(diffImg_path) as src:\n",
    "    # Extract band names and image bounds\n",
    "    band_names = src.descriptions\n",
    "    bounds = src.bounds\n",
    "\n",
    "    # Calculate the center latitude and longitude for the map\n",
    "    center_lat = (bounds.top + bounds.bottom) / 2\n",
    "    center_lon = (bounds.left + bounds.right) / 2\n",
    "\n",
    "    # Initialize a folium map centered at the calculated location\n",
    "    m = folium.Map(location=[center_lat, center_lon], zoom_start=18, tiles='CartoDB positron')\n",
    "\n",
    "    # Function to convert a band to RGBA format using a colormap\n",
    "    def rgba_from_band_01(band, cmap_name='gray', vmin=None, vmax=None):\n",
    "        arr = np.ma.filled(band, np.nan).astype(float)  # Replace masked values with NaN\n",
    "        arr = np.clip((arr - vmin) / (vmax - vmin), 0.0, 1.0)  # Normalize to [0, 1]\n",
    "        rgba = np.zeros((*arr.shape, 4), dtype=np.uint8)  # Initialize RGBA array\n",
    "        mask = ~np.isnan(arr)  # Mask for valid data\n",
    "        rgba[mask, :3] = (cm.get_cmap(cmap_name)(arr[mask])[:, :3] * 255).astype(np.uint8)  # Apply colormap\n",
    "        rgba[mask, 3] = 255  # Set alpha channel for valid data\n",
    "        return rgba\n",
    "\n",
    "    # Loop through the first two bands and add them as overlays to the map\n",
    "    for i in range(1, 3):\n",
    "        band = src.read(i, masked=True)  # Read the band as a masked array\n",
    "        rgba = rgba_from_band_01(band, 'gray', vmin=0, vmax=5)  # Convert to RGBA\n",
    "        folium.raster_layers.ImageOverlay(\n",
    "            image=rgba,\n",
    "            bounds=[[bounds.bottom, bounds.left], [bounds.top, bounds.right]],\n",
    "            name=f\"Day-of-week {i-1} ({['Sunday', 'Monday'][i-1]})\",  # Add a descriptive name\n",
    "            opacity=1,  # Set overlay opacity\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Add a satellite tile layer and a layer control to the map\n",
    "    folium.TileLayer('Esri.WorldImagery', name='Satellite').add_to(m)\n",
    "    folium.LayerControl().add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing 01_prep, we can now extract the shapes with periodic appearance differences using 02_mktShape.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Create Market Shape Using Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the input file\n",
    "file_path = f\"{repl_pkg_path}/code\\\\data_derivation\\\\02_mktShape.txt\"\n",
    "\n",
    "# Read the content of the input file\n",
    "with open(file_path, \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Replace placeholders in the file content with actual variable values\n",
    "content = (content.replace(\"INSERT_LOC_HERE\", loc)\n",
    "                  .replace(\"INSERT_LOC_GROUP_HERE\", locGroup)\n",
    "                  .replace(\"INSERT_BUCKET_HERE\", bucket)\n",
    "                  .replace(\"INSERT_COUNTRY_HERE\", country))\n",
    "\n",
    "# Define the path for the new file with \"_torun\" suffix\n",
    "new_file_path = file_path.replace(\".txt\", \"_torun.txt\")\n",
    "\n",
    "# Write the updated content to the new file\n",
    "with open(new_file_path, \"w\") as new_file:\n",
    "    new_file.write(content)\n",
    "\n",
    "# Execute the updated script using Node.js and the ee-runner tool\n",
    "subprocess.call([\n",
    "    nodePath,                # Path to the Node.js executable\n",
    "    eerunnerPath,            # Path to the ee-runner script\n",
    "    new_file_path,           # Path to the updated script file\n",
    "    f\"--project={GEEproject}\"  # Specify the GEE project as a command-line argument\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell presents the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the shapefile\n",
    "shapefile_path = os.path.join(\n",
    "    repl_pkg_path, \n",
    "    \"datasets\", \n",
    "    \"intermediate_outputs\", \n",
    "    f\"{locGroup}_shapes_shp_MpM6_{locGroup}{loc}.shp\"\n",
    ")\n",
    "\n",
    "# Load the shapefile using GeoPandas\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Filter rows where 'subStrictn' equals 100 (removes rings for visualization purposes)\n",
    "gdf = gdf[gdf['subStrictn'] == 100]\n",
    "\n",
    "# Filter the GeoDataFrame to keep:\n",
    "# 1. Shapes with the smallest 'strictness' for each 'weekdayShp'\n",
    "# 2. Shapes with 'strictness' values that are multiples of four\n",
    "idx_min_strictness = gdf.groupby('weekdayShp')['strictness'].idxmin()\n",
    "idx_multiple_of_four = gdf[gdf['strictness'] % 4 == 0].index\n",
    "combined_indices = pd.Index(idx_min_strictness).union(pd.Index(idx_multiple_of_four))\n",
    "gdf = gdf.loc[combined_indices]\n",
    "\n",
    "# Assign a color to each unique value of 'strictness' based on its rank\n",
    "strictness_colors = {\n",
    "    value: cm.get_cmap('viridis')(rank / len(strictness_values))\n",
    "    for rank, value in enumerate(sorted(strictness_values))\n",
    "}\n",
    "\n",
    "# Sort the GeoDataFrame by 'weekdayShp' (ascending) and 'strictness' (descending)\n",
    "gdf = gdf.sort_values(by=['weekdayShp', 'strictness'], ascending=[True, False])\n",
    "\n",
    "# Calculate the centroid of the shapefile's geometry to center the map\n",
    "centroid = gdf.geometry.unary_union.centroid\n",
    "m = folium.Map(location=[centroid.y, centroid.x], zoom_start=18, tiles='CartoDB positron')\n",
    "\n",
    "# Add the shapes to the map with colors based on 'strictness'\n",
    "for _, row in gdf.iterrows():\n",
    "    color = f\"#{int(strictness_colors[row['strictness']][0] * 255):02x}\" \\\n",
    "            f\"{int(strictness_colors[row['strictness']][1] * 255):02x}\" \\\n",
    "            f\"{int(strictness_colors[row['strictness']][2] * 255):02x}\"\n",
    "    folium.GeoJson(\n",
    "        data=row['geometry'],\n",
    "        name=f\"Weekday {int(row['weekdayShp'])}, Strictness {row['strictness']}\",\n",
    "        style_function=lambda x, color=color: {'color': color, 'weight': 2, 'fillOpacity': 0.5}\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add a satellite tile layer and a layer control to the map\n",
    "folium.TileLayer('Esri.WorldImagery', name='Satellite').add_to(m)\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is at least one shape in the output 02_mktShape that is associated with StrictnessRank<20 (the threshold shown in Fig. 2), or if the detected shape is manually assessed to identify a marketplace despite higher values of StrictnessRank, we execute the following step, 03_actPrep. This step generates a .tif where each band represents the appearance differences by captured image in the area covered by the detected shape. This data will subsequently be exported as a CSV for further processing. Note that at this point, we hanve't determined yet which of the detected shapes represents the actual market. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Create Image Collection for Activity Analysis in Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the input file\n",
    "file_path = f\"{repl_pkg_path}/code\\\\data_derivation\\\\03_actPrep.txt\"\n",
    "\n",
    "# Read the content of the input file\n",
    "with open(file_path, \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Replace placeholders in the file content with actual variable values\n",
    "content = (content.replace(\"INSERT_LOC_HERE\", loc)\n",
    "                  .replace(\"INSERT_LOC_GROUP_HERE\", locGroup)\n",
    "                  .replace(\"INSERT_BUCKET_HERE\", bucket)\n",
    "                  .replace(\"INSERT_COUNTRY_HERE\", country))\n",
    "\n",
    "# Define the path for the new file with \"_torun\" suffix\n",
    "new_file_path = file_path.replace(\".txt\", \"_torun.txt\")\n",
    "\n",
    "# Write the updated content to the new file\n",
    "with open(new_file_path, \"w\") as new_file:\n",
    "    new_file.write(content)\n",
    "\n",
    "# Execute the updated script using Node.js and the ee-runner tool\n",
    "subprocess.call([\n",
    "    nodePath,                # Path to the Node.js executable\n",
    "    eerunnerPath,            # Path to the ee-runner script\n",
    "    new_file_path,           # Path to the updated script file\n",
    "    f\"--project={GEEproject}\"  # Specify the GEE project as a command-line argument\n",
    "])\n",
    "\n",
    "# Note: The resulting image is stored in datasets/intermediate_outputs/{loc}_actPrep.tif\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final steps in GEE converts the output from 03_actPrep into a CSV and export a second CSV with the properties of each of the images, such as cloud cover or acquisition time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Create Activity Output in Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the input file\n",
    "file_path = f\"{repl_pkg_path}/code\\\\data_derivation\\\\04_activity.txt\"\n",
    "\n",
    "# Read the content of the input file\n",
    "with open(file_path, \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Replace placeholders in the file content with actual variable values\n",
    "content = (content.replace(\"INSERT_LOC_HERE\", loc)\n",
    "                  .replace(\"INSERT_LOC_GROUP_HERE\", locGroup)\n",
    "                  .replace(\"INSERT_BUCKET_HERE\", bucket)\n",
    "                  .replace(\"INSERT_COUNTRY_HERE\", country))\n",
    "\n",
    "# Define the path for the new file with \"_torun\" suffix\n",
    "new_file_path = file_path.replace(\".txt\", \"_torun.txt\")\n",
    "\n",
    "# Write the updated content to the new file\n",
    "with open(new_file_path, \"w\") as new_file:\n",
    "    new_file.write(content)\n",
    "\n",
    "# Execute the updated script using Node.js and the ee-runner tool\n",
    "subprocess.call([\n",
    "    nodePath,                # Path to the Node.js executable\n",
    "    eerunnerPath,            # Path to the ee-runner script\n",
    "    new_file_path,           # Path to the updated script file\n",
    "    f\"--project={GEEproject}\"  # Specify the GEE project as a command-line argument\n",
    "])\n",
    "\n",
    "# Define the path to the input file\n",
    "file_path = f\"{repl_pkg_path}/code\\\\data_derivation\\\\04a_properties.txt\"\n",
    "\n",
    "# Read the content of the input file\n",
    "with open(file_path, \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Replace placeholders in the file content with actual variable values\n",
    "content = (content.replace(\"INSERT_LOC_HERE\", loc)\n",
    "                  .replace(\"INSERT_LOC_GROUP_HERE\", locGroup)\n",
    "                  .replace(\"INSERT_BUCKET_HERE\", bucket)\n",
    "\n",
    "# Define the path for the new file with \"_torun\" suffix\n",
    "new_file_path = file_path.replace(\".txt\", \"_torun.txt\")\n",
    "\n",
    "# Write the updated content to the new file\n",
    "with open(new_file_path, \"w\") as new_file:\n",
    "    new_file.write(content)\n",
    "\n",
    "# Execute the updated script using Node.js and the ee-runner tool\n",
    "subprocess.call([\n",
    "    nodePath,                # Path to the Node.js executable\n",
    "    eerunnerPath,            # Path to the ee-runner script\n",
    "    new_file_path,           # Path to the updated script file\n",
    "    f\"--project={GEEproject}\"  # Specify the GEE project as a command-line argument\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now analyze the exported series of appearance differences for each ring to identify the market's fringe. Using this information, we construct the activity measure as the series of activity differences within the identified fringe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Create Activity Measure in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy\n",
    "from data_derivation.activity_functions import activity_processor\n",
    "\n",
    "# Upload activity data for the specified location\n",
    "df = activity_processor(loc, bucket, locGroup, country)\n",
    "\n",
    "# Convert Stata daily date numeric to datetime if necessary\n",
    "if not np.issubdtype(df['date'].dtype, np.datetime64):\n",
    "    df['date'] = pd.to_datetime(df['date'], unit='D', origin='1960-01-01')\n",
    "\n",
    "# Add market code and ID columns\n",
    "df['mktid'] = loc\n",
    "\n",
    "# Define the target date and range for filtering\n",
    "target = pd.Timestamp('2018-02-05')\n",
    "rng = 10\n",
    "\n",
    "# Filter the dataframe for the target date range, valid activity measures, and specific instrument\n",
    "df1 = df[\n",
    "    df['date'].between(target - pd.Timedelta(days=rng), target + pd.Timedelta(days=rng))\n",
    "    & df['activity_measure_norm'].notna()\n",
    "    & (df['instrument'] == 'PS2')\n",
    "].copy()\n",
    "\n",
    "# Count market-day observations per market\n",
    "df1['countMktDayObs'] = df1.groupby('mktid')['mktDay'].transform('sum')\n",
    "\n",
    "# Print the count of markets with exactly 4 market-day observations\n",
    "print(df1.loc[df1['countMktDayObs'] == 4, 'mktid'].value_counts())\n",
    "\n",
    "# Filter for rows where mktDay is either 0 (non-market day) or 1 (market day)\n",
    "df1 = df1[df1['mktDay'].isin([0, 1])].copy()\n",
    "\n",
    "# Create a two-letter weekday + day-of-month label (e.g., \"Mo 05\")\n",
    "dow2 = df1['date'].dt.day_name().map({\n",
    "    'Monday': 'Mo', 'Tuesday': 'Tu', 'Wednesday': 'We',\n",
    "    'Thursday': 'Th', 'Friday': 'Fr', 'Saturday': 'Sa', 'Sunday': 'Su'\n",
    "})\n",
    "df1['date_text2'] = dow2 + ' ' + df1['date'].dt.strftime('%d')\n",
    "\n",
    "# Drop duplicate rows based on market ID and date, and sort by date\n",
    "df1 = df1.drop_duplicates(subset=['mktid', 'date']).sort_values('date')\n",
    "\n",
    "# Plot bar chart for market activity on non-market vs market days\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Define colors for non-market and market days\n",
    "c_non = '#95d1c7'  # Light green\n",
    "c_mkt = '#2a9d8f'  # Dark green\n",
    "\n",
    "# Separate data for non-market and market days\n",
    "d0 = df1[df1['mktDay'] == 0]\n",
    "d1 = df1[df1['mktDay'] == 1]\n",
    "\n",
    "# Plot bars for non-market and market days\n",
    "ax.bar(d0['date'], d0['activity_measure_norm'], width=0.7, color=c_non, label='Non-market days')\n",
    "ax.bar(d1['date'], d1['activity_measure_norm'], width=0.7, color=c_mkt, label='Market days')\n",
    "\n",
    "# Set plot title and labels\n",
    "ax.set_title(\"Valid imagery acquisitions, Jan - Feb '18\")\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Market activity index')\n",
    "\n",
    "# Add grid lines for the y-axis\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "\n",
    "# Set x-axis tick labels to the two-letter weekday + day format\n",
    "ax.set_xticks(df1['date'])\n",
    "ax.set_xticklabels(df1['date_text2'], rotation=45, ha='right')\n",
    "\n",
    "# Set y-axis limits to match the range in Stata\n",
    "ax.set_ylim(-10, 100)\n",
    "\n",
    "# Add annotations near the left side of the plot\n",
    "left_x = df1['date'].max() - pd.Timedelta(days=4)\n",
    "ax.text(left_x, -7, \"Non-market days\", color=c_non, ha='center', va='bottom')\n",
    "ax.text(left_x, 95, \"Market days\", color=c_mkt, ha='center', va='top')\n",
    "\n",
    "# Remove the legend for a cleaner plot\n",
    "ax.legend().remove()\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
